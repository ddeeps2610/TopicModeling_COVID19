{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic_Modeling_On_Tweets_Around_COVID19\n",
    "In this notebook, we explore the various topics people are talking about Corona Virus Disease 2019(COVID-19) in Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/deepakawari/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tweepy as tw\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "'''\n",
    "Loading Gensim and nltk libraries\n",
    "'''\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "# Other stop_words: gensim.parsing.preprocessing.STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure notebook display to show data from pandas dataframe more clearly.\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.width',150)\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading data\n",
    "If the tweets data file is available, then load the data from the file else read the tweets from the Tweepy API. \n",
    "\n",
    "## Loading data from Twitter API:\n",
    "To load the data from Twitter using Tweepy API, you'll have to create Developer account with Twitter. Then download the credentials to authenticate using Tweepy API. Please do not share these credentials with anybody else. \n",
    "* Here is the link to [apply for twitter developer access](https://developer.twitter.com/en/apply-for-access)\n",
    "* You can follow the below code to use Tweepy API to authenticate and load the data. Here is the [Tweepy Documentation for reference](http://docs.tweepy.org/en/latest/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.246511e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ALPublicHealth: State Health Officer Dr. Scott Harris has issued a stay at home order and strict quarantine requirements. Read our full‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.246511e+18</td>\n",
       "      <td>Portland, oregon</td>\n",
       "      <td>RT @Carol_D_Johnson: Thank you nurses for helping to keep us healthy  ‚ù§ #COVID19 \\n#StayHomeSaveLives \\n#coronavirus https://t.co/HGv0HfuTgt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.246511e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Surgeon_General: #TogetherApart we can slow the spread of #COVID19. https://t.co/8JIBxQFpjv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.246511e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @SkyNews: Are smokers at greater risk of contracting #coronavirus?\\n\\nDr Ellie Cannon says while we are all at equal risk of contracting #‚Ä¶</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.246511e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @evankirstel: üò± The video of a 3D model from a CT scan shows the extent to which the #COVID19 has damaged the lung tissue  #StayHome #St‚Ä¶</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id          Location  \\\n",
       "0  1.246511e+18               NaN   \n",
       "1  1.246511e+18  Portland, oregon   \n",
       "2  1.246511e+18               NaN   \n",
       "3  1.246511e+18               NaN   \n",
       "4  1.246511e+18               NaN   \n",
       "\n",
       "                                                                                                                                             Text  \\\n",
       "0    RT @ALPublicHealth: State Health Officer Dr. Scott Harris has issued a stay at home order and strict quarantine requirements. Read our full‚Ä¶   \n",
       "1    RT @Carol_D_Johnson: Thank you nurses for helping to keep us healthy  ‚ù§ #COVID19 \\n#StayHomeSaveLives \\n#coronavirus https://t.co/HGv0HfuTgt   \n",
       "2                                                 RT @Surgeon_General: #TogetherApart we can slow the spread of #COVID19. https://t.co/8JIBxQFpjv   \n",
       "3  RT @SkyNews: Are smokers at greater risk of contracting #coronavirus?\\n\\nDr Ellie Cannon says while we are all at equal risk of contracting #‚Ä¶   \n",
       "4    RT @evankirstel: üò± The video of a 3D model from a CT scan shows the extent to which the #COVID19 has damaged the lung tissue  #StayHome #St‚Ä¶   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Load the data. Set the LoadFromTwitter to True if you want to override loading the data afresh from twitter.\n",
    "'''\n",
    "LoadFromTwitter = False\n",
    "\n",
    "fileName = '../data/tweets.csv'\n",
    "tweetsDF = None\n",
    "\n",
    "# Load the data\n",
    "if os.path.exists(fileName) and not LoadFromTwitter:\n",
    "    tweetsDF = pd.read_csv(fileName)\n",
    "else:\n",
    "    from TwitterDevSecrets import getTwitterDevCreds\n",
    "    consumer_key, consumer_secret, access_token, access_secret = getTwitterDevCreds()\n",
    "\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "    # Set the wait_on_rate_limit and wait_on_rate_limit_notify to True\n",
    "    # wait_on_rate_limit ‚Äì \n",
    "    #    Whether or not to automatically wait for rate limits to replenish\n",
    "    # wait_on_rate_limit_notify ‚Äì \n",
    "    #    Whether or not to print a notification when Tweepy is waiting \n",
    "    #    for rate limits to replenish\n",
    "    api = tw.API(\n",
    "        auth, \n",
    "        wait_on_rate_limit=True, \n",
    "        wait_on_rate_limit_notify=True)\n",
    "\n",
    "    # Define the search term and the date_since date as variables\n",
    "    search_words = \"#covid OR #covid19 OR #COVID OR #COVID19 OR #ncov OR #corona OR #coronaviru\"\n",
    "    date_since = \"2020-03-16\"\n",
    "    \n",
    "    # Read the tweets\n",
    "    tweets = tw.Cursor(api.search, \n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   since=date_since)\n",
    "\n",
    "    # extract the data in pandas dataframe\n",
    "    # Other parameters: tweet.user.screen_name, retweet_counts, favorite_counts\n",
    "    tweetsDF = pd.DataFrame()\n",
    "    for tweet in tweets.items(1000):\n",
    "        id = tweet.id\n",
    "        text = tweet.text\n",
    "        loc = tweet.user.location\n",
    "        tweetsDF = tweetsDF.append({'Id':id, 'Text':text, 'Location':loc},ignore_index=True)\n",
    "    \n",
    "    tweetsDF['index'] = tweetsDF.index\n",
    "    \n",
    "    # Save the new set of tweets in the file.\n",
    "    tweetsDF.to_csv(fileName,index=False)\n",
    "\n",
    "# Tweets loaded\n",
    "tweetsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @Carol_D_Johnson: Thank you nurses for helping to keep us healthy  ‚ù§ #COVID19 \\n#StayHomeSaveLives \\n#coronavirus https://t.co/HGv0HfuTgt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.Text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Data preprocessing\n",
    "We will perform the following data processing steps:\n",
    "\n",
    "* Tweet Preprocessing:\n",
    "> * Remove the leading **RT** - RT indicates that the user is re-posting someone else's tweet. We can remove this token.\n",
    "> * Remove the references to other accounts. The other accounts are usually referenced with '@' symbol.\n",
    "> * Remove urls mentioned in the tweets.\n",
    "\n",
    "* Generic text preprocessing:\n",
    "> * **Tokenization**: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "> * Remove words that have fewer than 3 characters.\n",
    "> * Remove all **stopwords**.\n",
    "> * **Lemmatize** the words: words in third person are changed to first person and verbs in past and future tenses are changed into present.  \n",
    "> Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words. \n",
    ">> WordnetLemmatizer: uses lookup table from nltk wordnet corpus to lookup the lemma to return a valid language lemma.\n",
    "> * **Stem** the Words: words are reduced to their root form.  \n",
    "> Stemming is the process of reducing inflection in words to their root forms such as \n",
    "mapping a group of words to the same stem even if the stem itself is not a valid word \n",
    "in the Language.\n",
    ">> PorterStemmer: is known for simplicity and ease. The algorithm does not follow linguistics rather a set of 05 rules for different cases that are applied in phases (step by step) to generate stems. This is the reason why PorterStemmer does not often generate stems that are actual English words.\n",
    ">> SnowballStemmer: One can generate its own set of rules for any language that is why Python nltk introduced SnowballStemmers that are used to create non-English Stemmers!\n",
    ">> LancasterStemmer: is simple, but heavy stemming due to iterations and over-stemming may occur. Over-stemming causes the stems to be not linguistic, or they may have no meaning.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data preprocessing for all tweets.\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def tweet_cleanup(text):\n",
    "    # Remove the leading RT from the tweet\n",
    "    text = text.replace('RT','')\n",
    "    # Remove the references to the account names starting with '@'\n",
    "    text = re.sub(r'(@[a-zA-Z]*)','',text)\n",
    "    # Remove the urls in the tweet.\n",
    "    text = re.sub(r'((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)','',text)\n",
    "    \n",
    "    return text\n",
    "  \n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text, stop_words=stop_words):\n",
    "    result=[]\n",
    "    text = tweet_cleanup(text)\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in stop_words and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet: \n",
      "['RT', '@ALPublicHealth:', 'State', 'Health', 'Officer', 'Dr.', 'Scott', 'Harris', 'has', 'issued', 'a', 'stay', 'at', 'home', 'order', 'and', 'strict', 'quarantine', 'requirements.', 'Read', 'our', 'full‚Ä¶']\n",
      "\n",
      "\n",
      "Preprocessed tweet: \n",
      "['state', 'health', 'offic', 'scott', 'harri', 'issu', 'stay', 'home', 'order', 'strict', 'quarantin', 'requir', 'read', 'full']\n"
     ]
    }
   ],
   "source": [
    "# Test the preprocessing and on a sample tweet\n",
    "tweet_num = 0\n",
    "sampleTweet = tweetsDF[tweetsDF['index'] == tweet_num].Text.iloc[0]\n",
    "\n",
    "print(\"Original tweet: \")\n",
    "words = []\n",
    "for word in sampleTweet.split():\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nPreprocessed tweet: \")\n",
    "print(preprocess(sampleTweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [state, health, offic, scott, harri, issu, stay, home, order, strict, quarantin, requir, read, full]\n",
       "1                                                             [nurs, help, keep, healthi, covid, coronavirus]\n",
       "2                                                                        [togetherapart, slow, spread, covid]\n",
       "3                    [smoker, greater, risk, contract, coronavirus, elli, cannon, say, equal, risk, contract]\n",
       "4                                      [video, model, scan, show, extent, covid, damag, lung, tissu, stayhom]\n",
       "5                      [leader, hous, parti, caucus, arizona, andi, bigg, think, spread, covid, much, possib]\n",
       "6                                                                                     [covid, test, administ]\n",
       "7           [keep, think, master, public, health, write, doctor, dissert, global, effort, tackl, aid, pandem]\n",
       "8    [ceylonblacktea, rich, theaflavin, help, increas, human, immun, covid, srilankatea, industri, successfu]\n",
       "9                                     [peopl, first, group, hospit, sick, place, infirmari, convert, convent]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess all tweets and generate a new processed tweet text dataset.\n",
    "\n",
    "processed_tweets = tweetsDF['Text'].map(preprocess)\n",
    "processed_tweets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1: Bag of words on the dataset\n",
    "Create a dictionary of words present in the preprocessed_tweets dataset. Gensim offers a great api for the same. This dictionary assigns a numerical id to each word so that you can work on the number representations of the word. This makes the data processing very easy than working on strings. \n",
    "\n",
    "Then create a corpus of Bag of words where words are represented by their numerical ids along with the frequency of occurence of that word in the tweet for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_tweets)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 full\n",
      "1 harri\n",
      "2 health\n",
      "3 home\n",
      "4 issu\n",
      "5 offic\n"
     ]
    }
   ],
   "source": [
    "# Check the id to word mapping from the dictionary created above\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the text corpus is very huge and sparse, we should try to minimize the amount of text being used for modeling. For this reason, let us remove very rare and very common words. Gensim dictionary object provides a good api to perform this operation.\n",
    "- words appearing less than 15 times\n",
    "- words appearing in more than 10% of all documents\n",
    "\n",
    "Then convert it into bag of word corpus with very rare and very common wordsd filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_tweets]\n",
    "\n",
    "# Test the Bag of Words representation of the tweet --> (token_id, token_count)\n",
    "bow_corpus[tweet_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"health\") appears 1 time.\n",
      "Word 1 (\"home\") appears 1 time.\n",
      "Word 2 (\"order\") appears 1 time.\n",
      "Word 3 (\"state\") appears 1 time.\n",
      "Word 4 (\"stay\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview BOW for our sample preprocessed tweet\n",
    "bow_tweet_0 = bow_corpus[tweet_num]\n",
    "\n",
    "for i in range(len(bow_tweet_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_tweet_0[i][0], \n",
    "                                                     dictionary[bow_tweet_0[i][0]], \n",
    "                                                     bow_tweet_0[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2: TF-IDF on the data set\n",
    "TFIDF, short for term frequency‚Äìinverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. Summing the Tf-idf of all possible terms and documents recovers the mutual information between documents and term taking into account all the specificities of their joint distribution.\n",
    "\n",
    "TF (Term Frequency) - number of times a term occurs in a document.\n",
    "IDF (Inverse Document Frequency) diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf-idf model object using models.TfidfModel\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# Apply transformation to the entire corpus\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"health\") TF-IDF score: 0.40009295170061265.\n",
      "Word 1 (\"home\") TF-IDF score: 0.44472924895798494.\n",
      "Word 2 (\"order\") TF-IDF score: 0.45253501051552114.\n",
      "Word 3 (\"state\") TF-IDF score: 0.47433139975516847.\n",
      "Word 4 (\"stay\") TF-IDF score: 0.4608289406979316.\n"
     ]
    }
   ],
   "source": [
    "# Preview TF-IDF for our sample preprocessed tweet\n",
    "tfidf_tweet_0 = corpus_tfidf[tweet_num]\n",
    "\n",
    "for i in range(len(tfidf_tweet_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") TF-IDF score: {}.\".format(tfidf_tweet_0[i][0], \n",
    "                                                     dictionary[tfidf_tweet_0[i][0]], \n",
    "                                                     tfidf_tweet_0[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Topic modeling, Visualizations and evaluations\n",
    "In this section we'll be building the topic models, visualize them and then evaluate the topic modeling. \n",
    "\n",
    "## Step 4.1: Modeling using Bag of Words\n",
    "In the topic modeling task, we'll have to provide the number of topics we want the model to cluster the tweets into. But how do we identify the number of topics? The best way to identify that is by visualizing the clusters itself. Start with a high number of topics like 10 or 20. Then map the clusters into a vector space and see if the clusters have clear boundaries. If the clusters overlap, reduce the number of clusters and visualize again. Repeat the process until you are satisfied with the segregation of the clusters.\n",
    "\n",
    "### Step 4.1.1: Running LDA using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the lda model using gensim.models.LdaMulticore on Bag of word corpus\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                       num_topics=3, \n",
    "                                       id2word = dictionary, \n",
    "                                       passes = 2, \n",
    "                                       workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.062*\"peopl\" + 0.033*\"death\" + 0.031*\"coronavirus\" + 0.030*\"keep\" + 0.027*\"like\" + 0.024*\"care\" + 0.023*\"spread\" + 0.023*\"today\" + 0.021*\"face\" + 0.021*\"human\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.054*\"case\" + 0.048*\"coronavirus\" + 0.045*\"work\" + 0.041*\"natur\" + 0.038*\"speak\" + 0.037*\"caus\" + 0.037*\"father\" + 0.036*\"murder\" + 0.036*\"poverti\" + 0.036*\"racism\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.052*\"pandem\" + 0.044*\"health\" + 0.044*\"mask\" + 0.041*\"home\" + 0.039*\"stay\" + 0.035*\"test\" + 0.033*\"order\" + 0.028*\"presid\" + 0.024*\"help\" + 0.023*\"public\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the words occuring in that topic and its relative weight\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the top words in each topic, we can identify the generic topic in that cluster. In the above clustering, the topics could be around  \n",
    "Topic 0: Take precautions    \n",
    "Topic 1: Impact of COVID-19 on work, racism, and poverty.   \n",
    "Topic 2: Quarantine and fight Corona virus  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Visualization using pyLDAVis for LDA with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2179951287154724218672534\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2179951287154724218672534_data = {\"mdsDat\": {\"x\": [0.19961726730052343, -0.10114444227867034, -0.09847282502185312], \"y\": [-0.0010792161252844818, -0.12041531533042563, 0.1214945314557101], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [38.65716552734375, 33.89848327636719, 27.444345474243164]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [69.0, 49.0, 47.0, 39.0, 39.0, 39.0, 33.0, 41.0, 40.0, 41.0, 37.0, 42.0, 44.0, 22.0, 33.0, 53.0, 58.0, 36.0, 74.0, 38.0, 17.0, 18.0, 18.0, 21.0, 37.0, 36.0, 16.0, 15.0, 26.0, 22.0, 38.57549285888672, 38.574134826660156, 38.51972198486328, 39.08568572998047, 39.58877182006836, 40.191837310791016, 44.58781433105469, 41.05835723876953, 13.655355453491211, 14.31758975982666, 13.418522834777832, 13.345067977905273, 14.82521915435791, 16.03598403930664, 48.898685455322266, 24.11419105529785, 14.6765718460083, 57.902523040771484, 19.020647048950195, 13.826069831848145, 10.937500953674316, 12.826176643371582, 19.123701095581055, 20.293621063232422, 14.079419136047363, 13.113734245300293, 17.190200805664062, 15.61044979095459, 11.572696685791016, 52.088294982910156, 20.397802352905273, 15.726219177246094, 15.221929550170898, 13.639001846313477, 13.705309867858887, 17.478891372680664, 14.695377349853516, 14.656790733337402, 14.646321296691895, 14.609508514404297, 15.498537063598633, 15.272173881530762, 31.44013786315918, 22.057722091674805, 58.368080139160156, 16.08063316345215, 20.054895401000977, 12.776440620422363, 14.75717544555664, 22.453357696533203, 15.4237699508667, 13.045330047607422, 19.71506118774414, 13.447131156921387, 19.04054832458496, 12.633013725280762, 13.24755859375, 27.916479110717773, 25.86976432800293, 18.945526123046875, 10.06675910949707, 13.704747200012207, 21.423948287963867, 10.708971977233887, 16.40898323059082, 17.130207061767578, 15.225712776184082, 29.43738555908203, 17.628707885742188, 16.56667137145996, 15.799521446228027, 14.776631355285645, 21.649940490722656, 16.573360443115234, 29.886436462402344, 14.079360961914062, 16.594308853149414, 14.653337478637695, 31.239931106567383, 17.62010383605957, 33.63153076171875, 39.888614654541016, 12.115120887756348, 25.557260513305664, 15.375232696533203, 16.705272674560547, 11.19855785369873, 12.603233337402344, 13.958622932434082, 33.73883056640625, 12.611385345458984, 27.03384780883789, 10.63567066192627, 10.744231224060059, 11.212385177612305, 17.64234161376953, 11.048873901367188, 14.053714752197266, 9.830140113830566, 6.606180667877197, 18.36005401611328, 6.363324165344238, 10.519267082214355, 10.021646499633789, 11.051831245422363], \"Term\": [\"peopl\", \"pandem\", \"natur\", \"poverti\", \"racism\", \"trut\", \"stay\", \"mask\", \"murder\", \"father\", \"home\", \"caus\", \"speak\", \"presid\", \"order\", \"health\", \"work\", \"death\", \"case\", \"keep\", \"ask\", \"global\", \"amaz\", \"worker\", \"like\", \"public\", \"import\", \"look\", \"spread\", \"doctor\", \"poverti\", \"racism\", \"trut\", \"murder\", \"father\", \"caus\", \"natur\", \"speak\", \"cast\", \"enough\", \"basi\", \"religion\", \"rich\", \"india\", \"work\", \"make\", \"either\", \"case\", \"report\", \"discrimin\", \"releas\", \"respons\", \"virus\", \"everyon\", \"poor\", \"break\", \"affect\", \"say\", \"confirm\", \"coronavirus\", \"fight\", \"patient\", \"trump\", \"govern\", \"protect\", \"amaz\", \"propaganda\", \"gullibl\", \"ceas\", \"narrat\", \"great\", \"often\", \"death\", \"spread\", \"peopl\", \"total\", \"face\", \"support\", \"die\", \"care\", \"medic\", \"crisi\", \"human\", \"updat\", \"never\", \"cover\", \"week\", \"keep\", \"like\", \"hospit\", \"recommend\", \"first\", \"today\", \"isol\", \"state\", \"time\", \"pleas\", \"coronavirus\", \"public\", \"help\", \"fight\", \"health\", \"presid\", \"ask\", \"stay\", \"look\", \"global\", \"import\", \"home\", \"worker\", \"mask\", \"pandem\", \"governor\", \"order\", \"call\", \"doctor\", \"life\", \"take\", \"nurs\", \"health\", \"send\", \"test\", \"lockdown\", \"nation\", \"equip\", \"public\", \"april\", \"trump\", \"china\", \"polic\", \"help\", \"isol\", \"keep\", \"like\", \"coronavirus\"], \"Total\": [69.0, 49.0, 47.0, 39.0, 39.0, 39.0, 33.0, 41.0, 40.0, 41.0, 37.0, 42.0, 44.0, 22.0, 33.0, 53.0, 58.0, 36.0, 74.0, 38.0, 17.0, 18.0, 18.0, 21.0, 37.0, 36.0, 16.0, 15.0, 26.0, 22.0, 39.489479064941406, 39.49093246459961, 39.49177932739258, 40.457489013671875, 41.3968620300293, 42.375614166259766, 47.04800796508789, 44.321197509765625, 15.107057571411133, 16.0283203125, 15.123391151428223, 15.127920150756836, 17.01508140563965, 18.943307876586914, 58.74215316772461, 29.275362014770508, 17.99876594543457, 74.93093872070312, 25.739501953125, 18.968873977661133, 15.166129112243652, 18.963476181030273, 28.53145980834961, 30.52812957763672, 22.07207489013672, 20.923580169677734, 27.6442928314209, 25.899776458740234, 20.196704864501953, 92.5775146484375, 41.11167907714844, 29.81240463256836, 30.998329162597656, 25.01679229736328, 26.81597137451172, 18.324399948120117, 15.433683395385742, 15.43413257598877, 15.434281349182129, 15.434202194213867, 16.399797439575195, 16.38962745666504, 36.6620979309082, 26.0560302734375, 69.3893814086914, 19.258995056152344, 24.130966186523438, 15.481045722961426, 18.291322708129883, 27.90400505065918, 19.326980590820312, 16.368179321289062, 25.200889587402344, 17.31848907470703, 25.285234451293945, 17.372329711914062, 18.49058723449707, 38.966243743896484, 37.00276184082031, 28.155048370361328, 15.4483003616333, 21.06366729736328, 33.63383102416992, 17.59070587158203, 28.1298770904541, 30.846012115478516, 27.69695472717285, 92.5775146484375, 36.33644104003906, 47.62582778930664, 41.11167907714844, 53.257755279541016, 22.99790382385254, 17.97956657409668, 33.85731506347656, 15.963956832885742, 18.936552047729492, 16.9144229888916, 37.81048583984375, 21.845115661621094, 41.75605010986328, 49.722782135009766, 15.878440856933594, 33.763885498046875, 20.790660858154297, 22.70594024658203, 15.784022331237793, 17.772708892822266, 20.768373489379883, 53.257755279541016, 21.605422973632812, 50.90328598022461, 20.647655487060547, 21.37395477294922, 22.584043502807617, 36.33644104003906, 23.322343826293945, 30.998329162597656, 22.546634674072266, 16.63755226135254, 47.62582778930664, 17.59070587158203, 38.966243743896484, 37.00276184082031, 92.5775146484375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9269999861717224, 0.9269000291824341, 0.9254999756813049, 0.9158999919891357, 0.9057999849319458, 0.8974999785423279, 0.8967000246047974, 0.8740000128746033, 0.849399983882904, 0.8375999927520752, 0.8307999968528748, 0.824999988079071, 0.8126999735832214, 0.7838000059127808, 0.7670000195503235, 0.7565000057220459, 0.746399998664856, 0.6926000118255615, 0.6478999853134155, 0.6341999769210815, 0.6236000061035156, 0.5594000220298767, 0.5504000186920166, 0.5421000123023987, 0.5008000135421753, 0.4832000136375427, 0.47540000081062317, 0.4440999925136566, 0.3935999870300293, 0.37529999017715454, 0.24959999322891235, 0.3107999861240387, 0.23919999599456787, 0.34380000829696655, 0.2791999876499176, 1.034600019454956, 1.0327999591827393, 1.0300999879837036, 1.0293999910354614, 1.026900053024292, 1.0253000259399414, 1.011199951171875, 0.9280999898910522, 0.9151999950408936, 0.9088000059127808, 0.9014000296592712, 0.8967999815940857, 0.8898000121116638, 0.8671000003814697, 0.8644999861717224, 0.8561999797821045, 0.8549000024795532, 0.8363000154495239, 0.8288000226020813, 0.7982000112533569, 0.7631999850273132, 0.7483999729156494, 0.7483000159263611, 0.7239000201225281, 0.6855999827384949, 0.6535000205039978, 0.6520000100135803, 0.6308000087738037, 0.5855000019073486, 0.5428000092506409, 0.4936000108718872, 0.48350000381469727, -0.06400000303983688, 0.35850000381469727, 0.025800000876188278, 0.12549999356269836, -0.20029999315738678, 1.2325999736785889, 1.2115999460220337, 1.1683000326156616, 1.1674000024795532, 1.1610000133514404, 1.1495000123977661, 1.1021000146865845, 1.0780999660491943, 1.0765999555587769, 1.07260000705719, 1.0225000381469727, 1.0145000219345093, 0.9912999868392944, 0.9861000180244446, 0.9498000144958496, 0.9492999911308289, 0.8956999778747559, 0.8364999890327454, 0.7547000050544739, 0.6601999998092651, 0.6295999884605408, 0.6051999926567078, 0.5928000211715698, 0.5705000162124634, 0.5458999872207642, 0.5019999742507935, 0.4629000127315521, 0.3693999946117401, 0.33980000019073486, 0.27619999647140503, -0.016499999910593033, -0.013199999928474426, -0.8324000239372253], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.328200101852417, -3.3282999992370605, -3.329699993133545, -3.3150999546051025, -3.302299976348877, -3.2871999740600586, -3.1833999156951904, -3.265899896621704, -4.366700172424316, -4.319399833679199, -4.384200096130371, -4.389699935913086, -4.2845001220703125, -4.205999851226807, -3.091099977493286, -3.7980000972747803, -4.294600009918213, -2.922100067138672, -4.035299777984619, -4.354300022125244, -4.588600158691406, -4.4293999671936035, -4.029900074005127, -3.9704999923706055, -4.336100101470947, -4.407199859619141, -4.136499881744385, -4.232900142669678, -4.532199859619141, -3.027899980545044, -3.965399980545044, -4.225500106811523, -4.2581000328063965, -4.3678998947143555, -4.363100051879883, -3.9885001182556152, -4.1620001792907715, -4.164599895477295, -4.165299892425537, -4.167799949645996, -4.108699798583984, -4.123499870300293, -3.401400089263916, -3.7558000087738037, -2.7827000617980957, -4.071899890899658, -3.8510000705718994, -4.3018999099731445, -4.157800197601318, -3.73799991607666, -4.11359977722168, -4.281099796295166, -3.8680999279022217, -4.250699996948242, -3.902899980545044, -4.313199996948242, -4.265699863433838, -3.5202999114990234, -3.596400022506714, -3.907900094985962, -4.540200233459473, -4.2316999435424805, -3.7850000858306885, -4.478400230407715, -4.051700115203857, -4.008600234985352, -4.126500129699707, -3.4672000408172607, -3.9800000190734863, -4.042099952697754, -4.0894999504089355, -4.156400203704834, -3.5632998943328857, -3.8304998874664307, -3.2409000396728516, -3.9935998916625977, -3.829200029373169, -3.9535999298095703, -3.1965999603271484, -3.769200086593628, -3.12280011177063, -2.952199935913086, -4.143799781799316, -3.39739990234375, -3.9054999351501465, -3.8225998878479004, -4.222499847412109, -4.104300022125244, -4.002200126647949, -3.1196000576019287, -4.103700160980225, -3.341200113296509, -4.274099826812744, -4.263899803161621, -4.22130012512207, -3.7679998874664307, -4.235899925231934, -3.9953999519348145, -4.352799892425537, -4.75029993057251, -3.728100061416626, -4.787700176239014, -4.285099983215332, -4.333499908447266, -4.2357001304626465]}, \"token.table\": {\"Topic\": [1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.6149551272392273, 0.25321683287620544, 0.14469532668590546, 0.9277247786521912, 0.3858960270881653, 0.12863200902938843, 0.47165071964263916, 0.05561869218945503, 0.05561869218945503, 0.9455177783966064, 0.8595955967903137, 0.06612273305654526, 0.6213085651397705, 0.28675779700279236, 0.09558593481779099, 0.09619703888893127, 0.1442955583333969, 0.7214778065681458, 0.1433486044406891, 0.7884172797203064, 0.03583715111017227, 0.7740460634231567, 0.12011060118675232, 0.10676497966051102, 0.9267191886901855, 0.06619422882795334, 0.9439391493797302, 0.023598477244377136, 0.023598477244377136, 0.9718625545501709, 0.044352516531944275, 0.5322301983833313, 0.44352516531944275, 0.5941563248634338, 0.09902605414390564, 0.34659120440483093, 0.5616914629936218, 0.3132510185241699, 0.11881934851408005, 0.17268840968608856, 0.7483164668083191, 0.11512560397386551, 0.12218829989433289, 0.794223964214325, 0.06109414994716644, 0.08182837814092636, 0.8455598950386047, 0.05455225333571434, 0.16401219367980957, 0.8200609683990479, 0.05467073246836662, 0.738051176071167, 0.21087177097797394, 0.052717942744493484, 0.22020669281482697, 0.04404133930802345, 0.7487027645111084, 0.833390474319458, 0.11111872643232346, 0.11111872643232346, 0.8734539747238159, 0.062389567494392395, 0.04427905008196831, 0.44279050827026367, 0.4870695471763611, 0.6551334857940674, 0.16378337144851685, 0.16378337144851685, 0.08288105577230453, 0.8288105726242065, 0.08288105577230453, 0.9662567973136902, 0.024156419560313225, 0.024156419560313225, 0.4864797592163086, 0.38918381929397583, 0.12161993980407715, 0.3323257863521576, 0.6646515727043152, 0.04747511446475983, 0.052807923406362534, 0.052807923406362534, 0.8977347016334534, 0.5596240758895874, 0.11991944909095764, 0.3197852075099945, 0.06297847628593445, 0.18893542885780334, 0.7557417154312134, 0.9146454334259033, 0.9718719124794006, 0.09388303756713867, 0.281649112701416, 0.6384046673774719, 0.2729611396789551, 0.35694918036460876, 0.3779461979866028, 0.052895378321409225, 0.1322384476661682, 0.8198783993721008, 0.10655282437801361, 0.6748345494270325, 0.24862326681613922, 0.03968114033341408, 0.7936227917671204, 0.1587245613336563, 0.1182422861456871, 0.8868170976638794, 0.8446254730224609, 0.05278909206390381, 0.10557818412780762, 0.056848201900720596, 0.6253302097320557, 0.3410892188549042, 0.025663238018751144, 0.7185706496238708, 0.2822956144809723, 0.19006562232971191, 0.1267104148864746, 0.6969072818756104, 0.0270250104367733, 0.702650249004364, 0.2702501118183136, 0.048431649804115295, 0.43588483333587646, 0.5327481627464294, 0.06264111399650574, 0.8769755363464355, 0.8198019862174988, 0.1707920879125595, 0.03415841609239578, 0.04789724946022034, 0.143691748380661, 0.8142532706260681, 0.10348227620124817, 0.7761170864105225, 0.10348227620124817, 0.9639747738838196, 0.02471730299293995, 0.971867561340332, 0.467859148979187, 0.04678591340780258, 0.5146450400352478, 0.9564698338508606, 0.0425097718834877, 0.02125488594174385, 0.7514266967773438, 0.23729263246059418, 0.048150137066841125, 0.28890082240104675, 0.6741018891334534, 0.06101419776678085, 0.9152129888534546, 0.029617443680763245, 0.23693954944610596, 0.7700535655021667, 0.04022300988435745, 0.1608920395374298, 0.8044602274894714, 0.5366893410682678, 0.1677154153585434, 0.30188775062561035, 0.10087998956441879, 0.8358627557754517, 0.057645708322525024, 0.3971555829048157, 0.5415757894515991, 0.03610505163669586, 0.6010499596595764, 0.4207349717617035, 0.6342856287956238, 0.045306116342544556, 0.3171428143978119, 0.9876047968864441, 0.0434822253882885, 0.9566089510917664, 0.971900224685669, 0.5220769047737122, 0.2983296811580658, 0.18645603954792023, 0.02752058207988739, 0.495370477437973, 0.495370477437973, 0.9875684976577759, 0.19419611990451813, 0.6473203897476196, 0.1294640749692917, 0.7253004312515259, 0.19780920445919037, 0.06593640148639679, 0.8593382239341736, 0.06610293686389923, 0.738165020942688, 0.03885079175233841, 0.19425395131111145, 0.6855283379554749, 0.31639769673347473, 0.05273294821381569, 0.8815708756446838, 0.058771390467882156, 0.058771390467882156, 0.6177659630775452, 0.11583111435174942, 0.2702726125717163, 0.18513870239257812, 0.23142337799072266, 0.6017007827758789, 0.925065279006958, 0.02256256714463234, 0.04512513428926468, 0.07675766199827194, 0.8443343043327332, 0.07675766199827194, 0.14219756424427032, 0.5687902569770813, 0.24884574115276337, 0.08860714733600616, 0.02953571453690529, 0.8860714435577393, 0.06459511816501617, 0.8397365808486938, 0.12919023633003235, 0.16879813373088837, 0.11253208667039871, 0.7314585447311401, 0.21609607338905334, 0.25538626313209534, 0.5304176211357117, 0.25935280323028564, 0.5511247515678406, 0.16209550201892853, 0.26758772134780884, 0.624371349811554, 0.08919590711593628, 0.10384757816791534, 0.8307806253433228, 0.05192378908395767, 0.48389706015586853, 0.06451960653066635, 0.45163723826408386, 0.9875472784042358, 0.025321725755929947, 0.1732252687215805, 0.7506428360939026, 0.05774175748229027, 0.6659315824508667, 0.24534320831298828, 0.1051470935344696, 0.054081570357084274, 0.7030604481697083, 0.27040785551071167, 0.834153950214386, 0.051070649176836014, 0.1191648542881012, 0.09155364334583282, 0.09155364334583282, 0.823982834815979], \"Term\": [\"affect\", \"affect\", \"affect\", \"amaz\", \"april\", \"april\", \"april\", \"ask\", \"ask\", \"ask\", \"basi\", \"basi\", \"break\", \"break\", \"break\", \"call\", \"call\", \"call\", \"care\", \"care\", \"care\", \"case\", \"case\", \"case\", \"cast\", \"cast\", \"caus\", \"caus\", \"caus\", \"ceas\", \"china\", \"china\", \"china\", \"confirm\", \"confirm\", \"confirm\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"cover\", \"cover\", \"cover\", \"crisi\", \"crisi\", \"crisi\", \"death\", \"death\", \"death\", \"die\", \"die\", \"die\", \"discrimin\", \"discrimin\", \"discrimin\", \"doctor\", \"doctor\", \"doctor\", \"either\", \"either\", \"either\", \"enough\", \"enough\", \"equip\", \"equip\", \"equip\", \"everyon\", \"everyon\", \"everyon\", \"face\", \"face\", \"face\", \"father\", \"father\", \"father\", \"fight\", \"fight\", \"fight\", \"first\", \"first\", \"first\", \"global\", \"global\", \"global\", \"govern\", \"govern\", \"govern\", \"governor\", \"governor\", \"governor\", \"great\", \"gullibl\", \"health\", \"health\", \"health\", \"help\", \"help\", \"help\", \"home\", \"home\", \"home\", \"hospit\", \"hospit\", \"hospit\", \"human\", \"human\", \"human\", \"import\", \"import\", \"india\", \"india\", \"india\", \"isol\", \"isol\", \"isol\", \"keep\", \"keep\", \"keep\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"lockdown\", \"lockdown\", \"lockdown\", \"look\", \"look\", \"make\", \"make\", \"make\", \"mask\", \"mask\", \"mask\", \"medic\", \"medic\", \"medic\", \"murder\", \"murder\", \"narrat\", \"nation\", \"nation\", \"nation\", \"natur\", \"natur\", \"natur\", \"never\", \"never\", \"nurs\", \"nurs\", \"nurs\", \"often\", \"often\", \"order\", \"order\", \"order\", \"pandem\", \"pandem\", \"pandem\", \"patient\", \"patient\", \"patient\", \"peopl\", \"peopl\", \"peopl\", \"pleas\", \"pleas\", \"pleas\", \"polic\", \"polic\", \"poor\", \"poor\", \"poor\", \"poverti\", \"presid\", \"presid\", \"propaganda\", \"protect\", \"protect\", \"protect\", \"public\", \"public\", \"public\", \"racism\", \"recommend\", \"recommend\", \"recommend\", \"releas\", \"releas\", \"releas\", \"religion\", \"religion\", \"report\", \"report\", \"report\", \"respons\", \"respons\", \"respons\", \"rich\", \"rich\", \"rich\", \"say\", \"say\", \"say\", \"send\", \"send\", \"send\", \"speak\", \"speak\", \"speak\", \"spread\", \"spread\", \"spread\", \"state\", \"state\", \"state\", \"stay\", \"stay\", \"stay\", \"support\", \"support\", \"support\", \"take\", \"take\", \"take\", \"test\", \"test\", \"test\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"total\", \"total\", \"total\", \"trump\", \"trump\", \"trump\", \"trut\", \"trut\", \"updat\", \"updat\", \"updat\", \"virus\", \"virus\", \"virus\", \"week\", \"week\", \"week\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2179951287154724218672534\", ldavis_el2179951287154724218672534_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2179951287154724218672534\", ldavis_el2179951287154724218672534_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2179951287154724218672534\", ldavis_el2179951287154724218672534_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.199617 -0.001079       1        1  38.657166\n",
       "0     -0.101144 -0.120415       2        1  33.898483\n",
       "2     -0.098473  0.121495       3        1  27.444345, topic_info=    Category       Freq         Term      Total  loglift  logprob\n",
       "20   Default  69.000000        peopl  69.000000  30.0000  30.0000\n",
       "14   Default  49.000000       pandem  49.000000  29.0000  29.0000\n",
       "34   Default  47.000000        natur  47.000000  28.0000  28.0000\n",
       "35   Default  39.000000      poverti  39.000000  27.0000  27.0000\n",
       "36   Default  39.000000       racism  39.000000  26.0000  26.0000\n",
       "38   Default  39.000000         trut  39.000000  25.0000  25.0000\n",
       "4    Default  33.000000         stay  33.000000  24.0000  24.0000\n",
       "22   Default  41.000000         mask  41.000000  23.0000  23.0000\n",
       "33   Default  40.000000       murder  40.000000  22.0000  22.0000\n",
       "32   Default  41.000000       father  41.000000  21.0000  21.0000\n",
       "1    Default  37.000000         home  37.000000  20.0000  20.0000\n",
       "31   Default  42.000000         caus  42.000000  19.0000  19.0000\n",
       "37   Default  44.000000        speak  44.000000  18.0000  18.0000\n",
       "95   Default  22.000000       presid  22.000000  17.0000  17.0000\n",
       "2    Default  33.000000        order  33.000000  16.0000  16.0000\n",
       "0    Default  53.000000       health  53.000000  15.0000  15.0000\n",
       "39   Default  58.000000         work  58.000000  14.0000  14.0000\n",
       "42   Default  36.000000        death  36.000000  13.0000  13.0000\n",
       "48   Default  74.000000         case  74.000000  12.0000  12.0000\n",
       "7    Default  38.000000         keep  38.000000  11.0000  11.0000\n",
       "84   Default  17.000000          ask  17.000000  10.0000  10.0000\n",
       "13   Default  18.000000       global  18.000000   9.0000   9.0000\n",
       "74   Default  18.000000         amaz  18.000000   8.0000   8.0000\n",
       "70   Default  21.000000       worker  21.000000   7.0000   7.0000\n",
       "27   Default  37.000000         like  37.000000   6.0000   6.0000\n",
       "15   Default  36.000000       public  36.000000   5.0000   5.0000\n",
       "47   Default  16.000000       import  16.000000   4.0000   4.0000\n",
       "73   Default  15.000000         look  15.000000   3.0000   3.0000\n",
       "9    Default  26.000000       spread  26.000000   2.0000   2.0000\n",
       "12   Default  22.000000       doctor  22.000000   1.0000   1.0000\n",
       "35    Topic1  38.575493      poverti  39.489479   0.9270  -3.3282\n",
       "36    Topic1  38.574135       racism  39.490932   0.9269  -3.3283\n",
       "38    Topic1  38.519722         trut  39.491779   0.9255  -3.3297\n",
       "33    Topic1  39.085686       murder  40.457489   0.9159  -3.3151\n",
       "32    Topic1  39.588772       father  41.396862   0.9058  -3.3023\n",
       "31    Topic1  40.191837         caus  42.375614   0.8975  -3.2872\n",
       "34    Topic1  44.587814        natur  47.048008   0.8967  -3.1834\n",
       "37    Topic1  41.058357        speak  44.321198   0.8740  -3.2659\n",
       "59    Topic1  13.655355         cast  15.107058   0.8494  -4.3667\n",
       "50    Topic1  14.317590       enough  16.028320   0.8376  -4.3194\n",
       "58    Topic1  13.418523         basi  15.123391   0.8308  -4.3842\n",
       "64    Topic1  13.345068     religion  15.127920   0.8250  -4.3897\n",
       "17    Topic1  14.825219         rich  17.015081   0.8127  -4.2845\n",
       "66    Topic1  16.035984        india  18.943308   0.7838  -4.2060\n",
       "39    Topic1  48.898685         work  58.742153   0.7670  -3.0911\n",
       "67    Topic1  24.114191         make  29.275362   0.7565  -3.7980\n",
       "61    Topic1  14.676572       either  17.998766   0.7464  -4.2946\n",
       "48    Topic1  57.902523         case  74.930939   0.6926  -2.9221\n",
       "43    Topic1  19.020647       report  25.739502   0.6479  -4.0353\n",
       "60    Topic1  13.826070    discrimin  18.968874   0.6342  -4.3543\n",
       "100   Topic1  10.937501       releas  15.166129   0.6236  -4.5886\n",
       "57    Topic1  12.826177      respons  18.963476   0.5594  -4.4294\n",
       "68    Topic1  19.123701        virus  28.531460   0.5504  -4.0299\n",
       "62    Topic1  20.293621      everyon  30.528130   0.5421  -3.9705\n",
       "63    Topic1  14.079419         poor  22.072075   0.5008  -4.3361\n",
       "86    Topic1  13.113734        break  20.923580   0.4832  -4.4072\n",
       "52    Topic1  17.190201       affect  27.644293   0.4754  -4.1365\n",
       "10    Topic1  15.610450          say  25.899776   0.4441  -4.2329\n",
       "93    Topic1  11.572697      confirm  20.196705   0.3936  -4.5322\n",
       "5     Topic1  52.088295  coronavirus  92.577515   0.3753  -3.0279\n",
       "65    Topic1  20.397802        fight  41.111679   0.2496  -3.9654\n",
       "45    Topic1  15.726219      patient  29.812405   0.3108  -4.2255\n",
       "98    Topic1  15.221930        trump  30.998329   0.2392  -4.2581\n",
       "40    Topic1  13.639002       govern  25.016792   0.3438  -4.3679\n",
       "89    Topic1  13.705310      protect  26.815971   0.2792  -4.3631\n",
       "74    Topic2  17.478891         amaz  18.324400   1.0346  -3.9885\n",
       "79    Topic2  14.695377   propaganda  15.433683   1.0328  -4.1620\n",
       "76    Topic2  14.656791      gullibl  15.434133   1.0301  -4.1646\n",
       "75    Topic2  14.646321         ceas  15.434281   1.0294  -4.1653\n",
       "77    Topic2  14.609509       narrat  15.434202   1.0269  -4.1678\n",
       "69    Topic2  15.498537        great  16.399797   1.0253  -4.1087\n",
       "21    Topic2  15.272174        often  16.389627   1.0112  -4.1235\n",
       "42    Topic2  31.440138        death  36.662098   0.9281  -3.4014\n",
       "9     Topic2  22.057722       spread  26.056030   0.9152  -3.7558\n",
       "20    Topic2  58.368080        peopl  69.389381   0.9088  -2.7827\n",
       "87    Topic2  16.080633        total  19.258995   0.9014  -4.0719\n",
       "94    Topic2  20.054895         face  24.130966   0.8968  -3.8510\n",
       "30    Topic2  12.776441      support  15.481046   0.8898  -4.3019\n",
       "83    Topic2  14.757175          die  18.291323   0.8671  -4.1578\n",
       "44    Topic2  22.453358         care  27.904005   0.8645  -3.7380\n",
       "29    Topic2  15.423770        medic  19.326981   0.8562  -4.1136\n",
       "54    Topic2  13.045330        crisi  16.368179   0.8549  -4.2811\n",
       "16    Topic2  19.715061        human  25.200890   0.8363  -3.8681\n",
       "88    Topic2  13.447131        updat  17.318489   0.8288  -4.2507\n",
       "78    Topic2  19.040548        never  25.285234   0.7982  -3.9029\n",
       "99    Topic2  12.633014        cover  17.372330   0.7632  -4.3132\n",
       "80    Topic2  13.247559         week  18.490587   0.7484  -4.2657\n",
       "7     Topic2  27.916479         keep  38.966244   0.7483  -3.5203\n",
       "27    Topic2  25.869764         like  37.002762   0.7239  -3.5964\n",
       "19    Topic2  18.945526       hospit  28.155048   0.6856  -3.9079\n",
       "91    Topic2  10.066759    recommend  15.448300   0.6535  -4.5402\n",
       "18    Topic2  13.704747        first  21.063667   0.6520  -4.2317\n",
       "28    Topic2  21.423948        today  33.633831   0.6308  -3.7850\n",
       "41    Topic2  10.708972         isol  17.590706   0.5855  -4.4784\n",
       "3     Topic2  16.408983        state  28.129877   0.5428  -4.0517\n",
       "46    Topic2  17.130207         time  30.846012   0.4936  -4.0086\n",
       "81    Topic2  15.225713        pleas  27.696955   0.4835  -4.1265\n",
       "5     Topic2  29.437386  coronavirus  92.577515  -0.0640  -3.4672\n",
       "15    Topic2  17.628708       public  36.336441   0.3585  -3.9800\n",
       "6     Topic2  16.566671         help  47.625828   0.0258  -4.0421\n",
       "65    Topic2  15.799521        fight  41.111679   0.1255  -4.0895\n",
       "0     Topic2  14.776631       health  53.257755  -0.2003  -4.1564\n",
       "95    Topic3  21.649940       presid  22.997904   1.2326  -3.5633\n",
       "84    Topic3  16.573360          ask  17.979567   1.2116  -3.8305\n",
       "4     Topic3  29.886436         stay  33.857315   1.1683  -3.2409\n",
       "73    Topic3  14.079361         look  15.963957   1.1674  -3.9936\n",
       "13    Topic3  16.594309       global  18.936552   1.1610  -3.8292\n",
       "47    Topic3  14.653337       import  16.914423   1.1495  -3.9536\n",
       "1     Topic3  31.239931         home  37.810486   1.1021  -3.1966\n",
       "70    Topic3  17.620104       worker  21.845116   1.0781  -3.7692\n",
       "22    Topic3  33.631531         mask  41.756050   1.0766  -3.1228\n",
       "14    Topic3  39.888615       pandem  49.722782   1.0726  -2.9522\n",
       "92    Topic3  12.115121     governor  15.878441   1.0225  -4.1438\n",
       "2     Topic3  25.557261        order  33.763885   1.0145  -3.3974\n",
       "85    Topic3  15.375233         call  20.790661   0.9913  -3.9055\n",
       "12    Topic3  16.705273       doctor  22.705940   0.9861  -3.8226\n",
       "53    Topic3  11.198558         life  15.784022   0.9498  -4.2225\n",
       "101   Topic3  12.603233         take  17.772709   0.9493  -4.1043\n",
       "8     Topic3  13.958623         nurs  20.768373   0.8957  -4.0022\n",
       "0     Topic3  33.738831       health  53.257755   0.8365  -3.1196\n",
       "23    Topic3  12.611385         send  21.605423   0.7547  -4.1037\n",
       "11    Topic3  27.033848         test  50.903286   0.6602  -3.3412\n",
       "25    Topic3  10.635671     lockdown  20.647655   0.6296  -4.2741\n",
       "26    Topic3  10.744231       nation  21.373955   0.6052  -4.2639\n",
       "72    Topic3  11.212385        equip  22.584044   0.5928  -4.2213\n",
       "15    Topic3  17.642342       public  36.336441   0.5705  -3.7680\n",
       "24    Topic3  11.048874        april  23.322344   0.5459  -4.2359\n",
       "98    Topic3  14.053715        trump  30.998329   0.5020  -3.9954\n",
       "55    Topic3   9.830140        china  22.546635   0.4629  -4.3528\n",
       "90    Topic3   6.606181        polic  16.637552   0.3694  -4.7503\n",
       "6     Topic3  18.360054         help  47.625828   0.3398  -3.7281\n",
       "41    Topic3   6.363324         isol  17.590706   0.2762  -4.7877\n",
       "7     Topic3  10.519267         keep  38.966244  -0.0165  -4.2851\n",
       "27    Topic3  10.021646         like  37.002762  -0.0132  -4.3335\n",
       "5     Topic3  11.051831  coronavirus  92.577515  -0.8324  -4.2357, token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "52        1  0.614955       affect\n",
       "52        2  0.253217       affect\n",
       "52        3  0.144695       affect\n",
       "74        2  0.927725         amaz\n",
       "24        1  0.385896        april\n",
       "24        2  0.128632        april\n",
       "24        3  0.471651        april\n",
       "84        1  0.055619          ask\n",
       "84        2  0.055619          ask\n",
       "84        3  0.945518          ask\n",
       "58        1  0.859596         basi\n",
       "58        3  0.066123         basi\n",
       "86        1  0.621309        break\n",
       "86        2  0.286758        break\n",
       "86        3  0.095586        break\n",
       "85        1  0.096197         call\n",
       "85        2  0.144296         call\n",
       "85        3  0.721478         call\n",
       "44        1  0.143349         care\n",
       "44        2  0.788417         care\n",
       "44        3  0.035837         care\n",
       "48        1  0.774046         case\n",
       "48        2  0.120111         case\n",
       "48        3  0.106765         case\n",
       "59        1  0.926719         cast\n",
       "59        3  0.066194         cast\n",
       "31        1  0.943939         caus\n",
       "31        2  0.023598         caus\n",
       "31        3  0.023598         caus\n",
       "75        2  0.971863         ceas\n",
       "55        1  0.044353        china\n",
       "55        2  0.532230        china\n",
       "55        3  0.443525        china\n",
       "93        1  0.594156      confirm\n",
       "93        2  0.099026      confirm\n",
       "93        3  0.346591      confirm\n",
       "5         1  0.561691  coronavirus\n",
       "5         2  0.313251  coronavirus\n",
       "5         3  0.118819  coronavirus\n",
       "99        1  0.172688        cover\n",
       "99        2  0.748316        cover\n",
       "99        3  0.115126        cover\n",
       "54        1  0.122188        crisi\n",
       "54        2  0.794224        crisi\n",
       "54        3  0.061094        crisi\n",
       "42        1  0.081828        death\n",
       "42        2  0.845560        death\n",
       "42        3  0.054552        death\n",
       "83        1  0.164012          die\n",
       "83        2  0.820061          die\n",
       "83        3  0.054671          die\n",
       "60        1  0.738051    discrimin\n",
       "60        2  0.210872    discrimin\n",
       "60        3  0.052718    discrimin\n",
       "12        1  0.220207       doctor\n",
       "12        2  0.044041       doctor\n",
       "12        3  0.748703       doctor\n",
       "61        1  0.833390       either\n",
       "61        2  0.111119       either\n",
       "61        3  0.111119       either\n",
       "50        1  0.873454       enough\n",
       "50        2  0.062390       enough\n",
       "72        1  0.044279        equip\n",
       "72        2  0.442791        equip\n",
       "72        3  0.487070        equip\n",
       "62        1  0.655133      everyon\n",
       "62        2  0.163783      everyon\n",
       "62        3  0.163783      everyon\n",
       "94        1  0.082881         face\n",
       "94        2  0.828811         face\n",
       "94        3  0.082881         face\n",
       "32        1  0.966257       father\n",
       "32        2  0.024156       father\n",
       "32        3  0.024156       father\n",
       "65        1  0.486480        fight\n",
       "65        2  0.389184        fight\n",
       "65        3  0.121620        fight\n",
       "18        1  0.332326        first\n",
       "18        2  0.664652        first\n",
       "18        3  0.047475        first\n",
       "13        1  0.052808       global\n",
       "13        2  0.052808       global\n",
       "13        3  0.897735       global\n",
       "40        1  0.559624       govern\n",
       "40        2  0.119919       govern\n",
       "40        3  0.319785       govern\n",
       "92        1  0.062978     governor\n",
       "92        2  0.188935     governor\n",
       "92        3  0.755742     governor\n",
       "69        2  0.914645        great\n",
       "76        2  0.971872      gullibl\n",
       "0         1  0.093883       health\n",
       "0         2  0.281649       health\n",
       "0         3  0.638405       health\n",
       "6         1  0.272961         help\n",
       "6         2  0.356949         help\n",
       "6         3  0.377946         help\n",
       "1         1  0.052895         home\n",
       "1         2  0.132238         home\n",
       "1         3  0.819878         home\n",
       "19        1  0.106553       hospit\n",
       "19        2  0.674835       hospit\n",
       "19        3  0.248623       hospit\n",
       "16        1  0.039681        human\n",
       "16        2  0.793623        human\n",
       "16        3  0.158725        human\n",
       "47        1  0.118242       import\n",
       "47        3  0.886817       import\n",
       "66        1  0.844625        india\n",
       "66        2  0.052789        india\n",
       "66        3  0.105578        india\n",
       "41        1  0.056848         isol\n",
       "41        2  0.625330         isol\n",
       "41        3  0.341089         isol\n",
       "7         1  0.025663         keep\n",
       "7         2  0.718571         keep\n",
       "7         3  0.282296         keep\n",
       "53        1  0.190066         life\n",
       "53        2  0.126710         life\n",
       "53        3  0.696907         life\n",
       "27        1  0.027025         like\n",
       "27        2  0.702650         like\n",
       "27        3  0.270250         like\n",
       "25        1  0.048432     lockdown\n",
       "25        2  0.435885     lockdown\n",
       "25        3  0.532748     lockdown\n",
       "73        2  0.062641         look\n",
       "73        3  0.876976         look\n",
       "67        1  0.819802         make\n",
       "67        2  0.170792         make\n",
       "67        3  0.034158         make\n",
       "22        1  0.047897         mask\n",
       "22        2  0.143692         mask\n",
       "22        3  0.814253         mask\n",
       "29        1  0.103482        medic\n",
       "29        2  0.776117        medic\n",
       "29        3  0.103482        medic\n",
       "33        1  0.963975       murder\n",
       "33        3  0.024717       murder\n",
       "77        2  0.971868       narrat\n",
       "26        1  0.467859       nation\n",
       "26        2  0.046786       nation\n",
       "26        3  0.514645       nation\n",
       "34        1  0.956470        natur\n",
       "34        2  0.042510        natur\n",
       "34        3  0.021255        natur\n",
       "78        2  0.751427        never\n",
       "78        3  0.237293        never\n",
       "8         1  0.048150         nurs\n",
       "8         2  0.288901         nurs\n",
       "8         3  0.674102         nurs\n",
       "21        1  0.061014        often\n",
       "21        2  0.915213        often\n",
       "2         1  0.029617        order\n",
       "2         2  0.236940        order\n",
       "2         3  0.770054        order\n",
       "14        1  0.040223       pandem\n",
       "14        2  0.160892       pandem\n",
       "14        3  0.804460       pandem\n",
       "45        1  0.536689      patient\n",
       "45        2  0.167715      patient\n",
       "45        3  0.301888      patient\n",
       "20        1  0.100880        peopl\n",
       "20        2  0.835863        peopl\n",
       "20        3  0.057646        peopl\n",
       "81        1  0.397156        pleas\n",
       "81        2  0.541576        pleas\n",
       "81        3  0.036105        pleas\n",
       "90        2  0.601050        polic\n",
       "90        3  0.420735        polic\n",
       "63        1  0.634286         poor\n",
       "63        2  0.045306         poor\n",
       "63        3  0.317143         poor\n",
       "35        1  0.987605      poverti\n",
       "95        1  0.043482       presid\n",
       "95        3  0.956609       presid\n",
       "79        2  0.971900   propaganda\n",
       "89        1  0.522077      protect\n",
       "89        2  0.298330      protect\n",
       "89        3  0.186456      protect\n",
       "15        1  0.027521       public\n",
       "15        2  0.495370       public\n",
       "15        3  0.495370       public\n",
       "36        1  0.987568       racism\n",
       "91        1  0.194196    recommend\n",
       "91        2  0.647320    recommend\n",
       "91        3  0.129464    recommend\n",
       "100       1  0.725300       releas\n",
       "100       2  0.197809       releas\n",
       "100       3  0.065936       releas\n",
       "64        1  0.859338     religion\n",
       "64        3  0.066103     religion\n",
       "43        1  0.738165       report\n",
       "43        2  0.038851       report\n",
       "43        3  0.194254       report\n",
       "57        1  0.685528      respons\n",
       "57        2  0.316398      respons\n",
       "57        3  0.052733      respons\n",
       "17        1  0.881571         rich\n",
       "17        2  0.058771         rich\n",
       "17        3  0.058771         rich\n",
       "10        1  0.617766          say\n",
       "10        2  0.115831          say\n",
       "10        3  0.270273          say\n",
       "23        1  0.185139         send\n",
       "23        2  0.231423         send\n",
       "23        3  0.601701         send\n",
       "37        1  0.925065        speak\n",
       "37        2  0.022563        speak\n",
       "37        3  0.045125        speak\n",
       "9         1  0.076758       spread\n",
       "9         2  0.844334       spread\n",
       "9         3  0.076758       spread\n",
       "3         1  0.142198        state\n",
       "3         2  0.568790        state\n",
       "3         3  0.248846        state\n",
       "4         1  0.088607         stay\n",
       "4         2  0.029536         stay\n",
       "4         3  0.886071         stay\n",
       "30        1  0.064595      support\n",
       "30        2  0.839737      support\n",
       "30        3  0.129190      support\n",
       "101       1  0.168798         take\n",
       "101       2  0.112532         take\n",
       "101       3  0.731459         take\n",
       "11        1  0.216096         test\n",
       "11        2  0.255386         test\n",
       "11        3  0.530418         test\n",
       "46        1  0.259353         time\n",
       "46        2  0.551125         time\n",
       "46        3  0.162096         time\n",
       "28        1  0.267588        today\n",
       "28        2  0.624371        today\n",
       "28        3  0.089196        today\n",
       "87        1  0.103848        total\n",
       "87        2  0.830781        total\n",
       "87        3  0.051924        total\n",
       "98        1  0.483897        trump\n",
       "98        2  0.064520        trump\n",
       "98        3  0.451637        trump\n",
       "38        1  0.987547         trut\n",
       "38        2  0.025322         trut\n",
       "88        1  0.173225        updat\n",
       "88        2  0.750643        updat\n",
       "88        3  0.057742        updat\n",
       "68        1  0.665932        virus\n",
       "68        2  0.245343        virus\n",
       "68        3  0.105147        virus\n",
       "80        1  0.054082         week\n",
       "80        2  0.703060         week\n",
       "80        3  0.270408         week\n",
       "39        1  0.834154         work\n",
       "39        2  0.051071         work\n",
       "39        3  0.119165         work\n",
       "70        1  0.091554       worker\n",
       "70        2  0.091554       worker\n",
       "70        3  0.823983       worker, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the visualizations, it'd be best to create 3 clusters instead of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3: Model evaluation\n",
    "Classify a sample tweet into the topics and then evaluate if the general topic matches with the tweet better than other topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test tweet is: 0: ['health', 'home', 'order', 'state', 'stay']\n",
      "\n",
      "Score: 0.8827516436576843\t \n",
      "Topic: 2 : 0.052*\"pandem\" + 0.044*\"health\" + 0.044*\"mask\" + 0.041*\"home\" + 0.039*\"stay\" + 0.035*\"test\" + 0.033*\"order\" + 0.028*\"presid\" + 0.024*\"help\" + 0.023*\"public\"\n",
      "\n",
      "Score: 0.06072410196065903\t \n",
      "Topic: 0 : 0.062*\"peopl\" + 0.033*\"death\" + 0.031*\"coronavirus\" + 0.030*\"keep\" + 0.027*\"like\" + 0.024*\"care\" + 0.023*\"spread\" + 0.023*\"today\" + 0.021*\"face\" + 0.021*\"human\"\n",
      "\n",
      "Score: 0.05652424693107605\t \n",
      "Topic: 1 : 0.054*\"case\" + 0.048*\"coronavirus\" + 0.045*\"work\" + 0.041*\"natur\" + 0.038*\"speak\" + 0.037*\"caus\" + 0.037*\"father\" + 0.036*\"murder\" + 0.036*\"poverti\" + 0.036*\"racism\"\n"
     ]
    }
   ],
   "source": [
    "# Our test tweet is \n",
    "print('Our test tweet is: {}: {}'.format(tweet_num, [dictionary[word[0]] for word in bow_corpus[tweet_num]]))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_corpus[tweet_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {} : {}\".format(score, index, lda_model.print_topic(index, 10))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample tweet is classified to Topic 2 with 88% probability. Topic 2 was centered around Quarantining and the sample tweet is classified correctly. Seems like the BOW based LDA model worked well.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Modeling using TF-IDF\n",
    "TF-IDF intends to reflect on the importance of each word in the tweet amongst other tweets. Thus it tries to create a better model instead of using mere Term Frequency as in Bag of words model. However, for TF-IDF to work it needs to have a good size of text in each document. However, tweet is usually very small in size. Thus, most of the times each word ends up being mentioned only once. Thus, TF-IDF doesn't work better for short texts. However, let's train the model and evaluate the performance and see how does it perform.\n",
    "\n",
    "### 4.2.1. Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train lda model using corpus_tfidf\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=3, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.044*\"test\" + 0.034*\"help\" + 0.031*\"time\" + 0.030*\"coronavirus\" + 0.030*\"spread\" + 0.027*\"like\" + 0.027*\"govern\" + 0.023*\"case\" + 0.022*\"health\" + 0.022*\"world\"\n",
      "\n",
      "\n",
      "Topic: 1 Word: 0.052*\"peopl\" + 0.035*\"work\" + 0.032*\"say\" + 0.031*\"home\" + 0.031*\"speak\" + 0.030*\"natur\" + 0.029*\"make\" + 0.029*\"caus\" + 0.029*\"father\" + 0.028*\"pandem\"\n",
      "\n",
      "\n",
      "Topic: 2 Word: 0.051*\"coronavirus\" + 0.043*\"mask\" + 0.043*\"case\" + 0.028*\"public\" + 0.027*\"keep\" + 0.027*\"protect\" + 0.026*\"first\" + 0.025*\"death\" + 0.023*\"stay\" + 0.023*\"patient\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the words occuring in that topic and its relative weight\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics from the above words:  \n",
    "Topic 0: President Trump's announcements   \n",
    "Topic 1: Impact of COVID in terms of patients, deaths and lockdowns.   \n",
    "Topic 2: Quarantine and fight the spread of COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2. Visualization using pyLDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2179951290965285093487438\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2179951290965285093487438_data = {\"mdsDat\": {\"x\": [0.07585181521671358, -0.17079927374292517, 0.09494745852621163], \"y\": [0.11527740241719171, -0.008283436411081738, -0.10699396600610998], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [34.795291900634766, 33.26156997680664, 31.943134307861328]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [23.0, 23.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 36.0, 16.0, 13.0, 18.0, 16.0, 33.0, 19.0, 23.0, 11.0, 15.0, 16.0, 15.0, 11.0, 12.0, 22.0, 12.0, 19.0, 12.0, 19.0, 12.0, 8.0, 22.052249908447266, 11.116374015808105, 6.80275297164917, 7.155335426330566, 10.946540832519531, 14.848145484924316, 7.582813739776611, 4.837783336639404, 4.804330825805664, 4.788198947906494, 15.778029441833496, 13.362966537475586, 8.443399429321289, 5.510540008544922, 10.94715404510498, 10.927567481994629, 5.887411594390869, 9.464057922363281, 7.562467098236084, 17.233285903930664, 8.485821723937988, 13.657109260559082, 6.92172384262085, 9.54107666015625, 8.02139663696289, 8.844735145568848, 7.166625022888184, 6.670332908630371, 7.428701400756836, 6.300740718841553, 11.270758628845215, 9.994938850402832, 14.896080017089844, 11.667957305908203, 7.682791233062744, 9.201370239257812, 7.438246250152588, 7.259204864501953, 14.668909072875977, 13.197689056396484, 13.170540809631348, 13.159278869628906, 13.362161636352539, 13.705578804016113, 13.87556266784668, 10.471900939941406, 10.246736526489258, 10.314840316772461, 14.235857963562012, 15.342263221740723, 8.612298011779785, 10.157415390014648, 7.993076324462891, 12.43663501739502, 14.690523147583008, 7.394184589385986, 16.968019485473633, 13.938870429992676, 9.880767822265625, 6.879884719848633, 24.77332878112793, 7.782260417938232, 8.035431861877441, 5.823746681213379, 7.415823936462402, 13.378310203552246, 4.951748847961426, 7.837668418884277, 8.882753372192383, 6.950748920440674, 7.425506114959717, 7.886380195617676, 12.037541389465332, 6.308627128601074, 5.694178581237793, 5.670969486236572, 5.629766941070557, 5.6281819343566895, 10.10618782043457, 6.632555961608887, 19.952774047851562, 8.867621421813965, 12.239706993103027, 7.149066925048828, 7.460005283355713, 12.961346626281738, 8.881083488464355, 10.076791763305664, 9.249479293823242, 7.848502159118652, 12.305882453918457, 7.176235675811768, 11.454080581665039, 7.663394451141357, 19.617671966552734, 10.569308280944824, 8.784343719482422, 6.056656360626221, 10.459094047546387, 6.535456657409668, 10.212078094482422, 23.6264705657959, 8.488895416259766, 7.398921012878418, 7.953731060028076, 6.586509704589844], \"Term\": [\"test\", \"mask\", \"speak\", \"poverti\", \"racism\", \"trut\", \"father\", \"murder\", \"caus\", \"peopl\", \"spread\", \"first\", \"time\", \"natur\", \"case\", \"say\", \"work\", \"look\", \"govern\", \"public\", \"protect\", \"never\", \"world\", \"help\", \"nation\", \"home\", \"human\", \"make\", \"crisi\", \"recommend\", \"test\", \"world\", \"discrimin\", \"enough\", \"nation\", \"spread\", \"poor\", \"basi\", \"religion\", \"cast\", \"time\", \"govern\", \"life\", \"rich\", \"china\", \"everyon\", \"either\", \"nurs\", \"india\", \"help\", \"countri\", \"like\", \"governor\", \"hospit\", \"presid\", \"virus\", \"respons\", \"confirm\", \"april\", \"week\", \"health\", \"fight\", \"coronavirus\", \"case\", \"state\", \"peopl\", \"pleas\", \"trump\", \"speak\", \"poverti\", \"racism\", \"trut\", \"murder\", \"father\", \"caus\", \"look\", \"human\", \"crisi\", \"natur\", \"say\", \"great\", \"call\", \"corona\", \"order\", \"home\", \"isol\", \"work\", \"make\", \"die\", \"support\", \"peopl\", \"equip\", \"break\", \"polic\", \"worker\", \"pandem\", \"releas\", \"pleas\", \"fight\", \"health\", \"coronavirus\", \"recommend\", \"first\", \"often\", \"ceas\", \"narrat\", \"gullibl\", \"propaganda\", \"never\", \"amaz\", \"mask\", \"total\", \"protect\", \"cover\", \"watch\", \"public\", \"face\", \"report\", \"medic\", \"ask\", \"keep\", \"must\", \"death\", \"doctor\", \"case\", \"stay\", \"live\", \"global\", \"patient\", \"take\", \"today\", \"coronavirus\", \"state\", \"send\", \"trump\", \"care\"], \"Total\": [23.0, 23.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 36.0, 16.0, 13.0, 18.0, 16.0, 33.0, 19.0, 23.0, 11.0, 15.0, 16.0, 15.0, 11.0, 12.0, 22.0, 12.0, 19.0, 12.0, 19.0, 12.0, 8.0, 23.626758575439453, 12.395339965820312, 7.617074966430664, 8.025693893432617, 12.306591033935547, 16.86849594116211, 8.63025951385498, 5.5719733238220215, 5.575118064880371, 5.576118469238281, 18.55624008178711, 15.743448257446289, 9.989862442016602, 6.523951530456543, 13.107110023498535, 13.201912879943848, 7.308793067932129, 12.404875755310059, 10.004037857055664, 22.934463500976562, 11.333070755004883, 19.24268341064453, 10.551133155822754, 15.137986183166504, 12.74332332611084, 14.354263305664062, 11.676610946655273, 11.23503303527832, 12.764126777648926, 12.262140274047852, 24.19536590576172, 21.535293579101562, 45.94805908203125, 33.00590515136719, 16.76936149597168, 36.507781982421875, 17.065704345703125, 18.60444450378418, 15.643105506896973, 14.093429565429688, 14.090730667114258, 14.091996192932129, 14.483394622802734, 14.935687065124512, 15.308341979980469, 11.55863094329834, 12.116035461425781, 12.245217323303223, 16.90573501586914, 19.320234298706055, 10.865982055664062, 13.210404396057129, 10.448047637939453, 16.42073631286621, 19.613815307617188, 9.88789176940918, 23.176156997680664, 19.227075576782227, 14.10850715637207, 10.109907150268555, 36.507781982421875, 11.938434600830078, 13.619612693786621, 9.962312698364258, 13.20418930053711, 25.660612106323242, 9.73656177520752, 17.065704345703125, 21.535293579101562, 24.19536590576172, 45.94805908203125, 8.730358123779297, 13.399345397949219, 7.039997577667236, 6.389342308044434, 6.3873491287231445, 6.385216236114502, 6.384506702423096, 11.537492752075195, 7.6100640296936035, 23.77332305908203, 10.68638801574707, 15.26826286315918, 8.952730178833008, 9.458765983581543, 16.756145477294922, 11.757040023803711, 14.931585311889648, 14.423129081726074, 12.309866905212402, 19.34979248046875, 11.805135726928711, 18.962963104248047, 12.84035873413086, 33.00590515136719, 17.93901252746582, 15.012910842895508, 10.422430038452148, 18.037391662597656, 11.53126335144043, 18.594947814941406, 45.94805908203125, 16.76936149597168, 14.369348526000977, 18.60444450378418, 15.54655647277832], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9866999983787537, 0.9467999935150146, 0.9426000118255615, 0.9409000277519226, 0.9386000037193298, 0.9280999898910522, 0.9262999892234802, 0.9143999814987183, 0.9068999886512756, 0.9032999873161316, 0.8934999704360962, 0.8917999863624573, 0.887499988079071, 0.886900007724762, 0.8755999803543091, 0.866599977016449, 0.8393999934196472, 0.785099983215332, 0.7759000062942505, 0.7699000239372253, 0.7663999795913696, 0.7128000259399414, 0.6341000199317932, 0.5940999984741211, 0.5928000211715698, 0.5715000033378601, 0.5674999952316284, 0.5343000292778015, 0.5144000053405762, 0.3898000121116638, 0.29170000553131104, 0.288100004196167, -0.07069999724626541, 0.015799999237060547, 0.2750999927520752, -0.32249999046325684, 0.22529999911785126, 0.11460000276565552, 1.0364999771118164, 1.035099983215332, 1.0332000255584717, 1.0322999954223633, 1.0202000141143799, 1.014799952507019, 1.002500057220459, 1.0019999742507935, 0.9332000017166138, 0.9291999936103821, 0.9289000034332275, 0.870199978351593, 0.8683000206947327, 0.8379999995231628, 0.8328999876976013, 0.8228999972343445, 0.8116999864578247, 0.8101999759674072, 0.7889999747276306, 0.7791000008583069, 0.7445999979972839, 0.7159000039100647, 0.7129999995231628, 0.6729000210762024, 0.5730999708175659, 0.5638999938964844, 0.5238000154495239, 0.44940000772476196, 0.4246000051498413, 0.32260000705718994, 0.2152000069618225, -0.14650000631809235, -0.7218000292778015, 1.0394999980926514, 1.034000039100647, 1.031499981880188, 1.0260000228881836, 1.0223000049591064, 1.0153000354766846, 1.0151000022888184, 1.0088000297546387, 1.0037000179290771, 0.9660000205039978, 0.9545999765396118, 0.9200999736785889, 0.9161999821662903, 0.9038000106811523, 0.8844000101089478, 0.8607000112533569, 0.7480000257492065, 0.6969000101089478, 0.691100001335144, 0.6886000037193298, 0.6434999704360962, 0.6370999813079834, 0.6251000165939331, 0.6209999918937683, 0.6122000217437744, 0.6053000092506409, 0.5983999967575073, 0.5961999893188477, 0.5734000205993652, 0.5418999791145325, 0.47609999775886536, 0.4603999853134155, 0.477400004863739, 0.2915000021457672, 0.2824000120162964], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.123699903488159, -3.8087000846862793, -4.299799919128418, -4.249300003051758, -3.8241000175476074, -3.519200086593628, -4.191199779510498, -4.640699863433838, -4.647600173950195, -4.651000022888184, -3.4584999084472656, -3.6245999336242676, -4.083700180053711, -4.510499954223633, -3.8239998817443848, -3.8257999420166016, -4.444300174713135, -3.969599962234497, -4.193900108337402, -3.370300054550171, -4.078700065612793, -3.6029000282287598, -4.28249979019165, -3.9614999294281006, -4.135000228881836, -4.037300109863281, -4.247700214385986, -4.319399833679199, -4.2118000984191895, -4.376399993896484, -3.7948999404907227, -3.9149999618530273, -3.5160000324249268, -3.7602999210357666, -4.178100109100342, -3.99780011177063, -4.2104997634887695, -4.234799861907959, -3.486299991607666, -3.5920000076293945, -3.594099998474121, -3.594899892807007, -3.5796000957489014, -3.5541999340057373, -3.5418999195098877, -3.8232998847961426, -3.845099925994873, -3.8385000228881836, -3.5162999629974365, -3.4414000511169434, -4.018799781799316, -3.853800058364868, -4.093500137329102, -3.651400089263916, -3.484800100326538, -4.171299934387207, -3.3406999111175537, -3.537400007247925, -3.8814001083374023, -4.2434000968933105, -2.9623000621795654, -4.120200157165527, -4.088200092315674, -4.410099983215332, -4.168399810791016, -3.578399896621704, -4.572299957275391, -4.113100051879883, -3.9879000186920166, -4.2332000732421875, -4.167099952697754, -4.066500186920166, -3.6435999870300293, -4.289700031280518, -4.392099857330322, -4.396200180053711, -4.403500080108643, -4.403800010681152, -3.8183999061584473, -4.23960018157959, -3.138200044631958, -3.949199914932251, -3.6268999576568604, -4.164599895477295, -4.122000217437744, -3.5696001052856445, -3.947700023651123, -3.8213999271392822, -3.9070000648498535, -4.071300029754639, -3.621500015258789, -4.160799980163574, -3.69320011138916, -4.095099925994873, -3.1552000045776367, -3.7736001014709473, -3.9586000442504883, -4.330399990081787, -3.78410005569458, -4.25439977645874, -3.808000087738037, -2.9691998958587646, -3.992799997329712, -4.130300045013428, -4.058000087738037, -4.246600151062012]}, \"token.table\": {\"Topic\": [1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.13140493631362915, 0.919834554195404, 0.5484119653701782, 0.07834456861019135, 0.39172282814979553, 0.16247129440307617, 0.24370694160461426, 0.6498851776123047, 0.897348165512085, 0.2936941087245941, 0.5873882174491882, 0.14684705436229706, 0.15139581263065338, 0.7569791078567505, 0.07569790631532669, 0.19296877086162567, 0.38593754172325134, 0.4502604901790619, 0.36357131600379944, 0.06059521809220314, 0.6059522032737732, 0.8966810703277588, 0.9145340323448181, 0.0653238594532013, 0.9390637874603271, 0.8392391800880432, 0.07629446685314178, 0.07629446685314178, 0.623051106929779, 0.356029212474823, 0.08900730311870575, 0.09571166336536407, 0.7656933069229126, 0.09571166336536407, 0.32645556330680847, 0.1523459404706955, 0.5223289132118225, 0.7058987021446228, 0.08823733776807785, 0.1764746755361557, 0.11169777065515518, 0.11169777065515518, 0.7818843722343445, 0.0816645398736, 0.8166453838348389, 0.0816645398736, 0.31640625, 0.10546875, 0.580078125, 0.21263766288757324, 0.7087922096252441, 0.07087922096252441, 0.9189879298210144, 0.3893972337245941, 0.07787944376468658, 0.6230355501174927, 0.8209289908409119, 0.13682149350643158, 0.13682149350643158, 0.8721987009048462, 0.2512892186641693, 0.6701046228408813, 0.08376307785511017, 0.8332126140594482, 0.15149319171905518, 0.07574659585952759, 0.17011083662509918, 0.7654988169670105, 0.06695373356342316, 0.9373522400856018, 0.06695373356342316, 0.464354008436203, 0.4179186224937439, 0.1393062025308609, 0.07463051378726959, 0.07463051378726959, 0.8955661654472351, 0.28784075379371643, 0.09594691544771194, 0.5756815075874329, 0.8257403373718262, 0.12703697383403778, 0.06351848691701889, 0.6634358763694763, 0.09477654844522476, 0.18955309689044952, 0.09203033894300461, 0.8282730579376221, 0.18406067788600922, 0.9396706223487854, 0.4546325206756592, 0.28931158781051636, 0.24798136949539185, 0.741242527961731, 0.08720500767230988, 0.17441001534461975, 0.10196894407272339, 0.764767050743103, 0.15295341610908508, 0.660589873790741, 0.2642359435558319, 0.13211797177791595, 0.08253525197505951, 0.8253524899482727, 0.08253525197505951, 0.7996770739555359, 0.19991926848888397, 0.202267587184906, 0.7079365253448486, 0.101133793592453, 0.1550404280424118, 0.20672056078910828, 0.6201617121696472, 0.8008118271827698, 0.10010147839784622, 0.10010147839784622, 0.7275492548942566, 0.207871213555336, 0.103935606777668, 0.06660933792591095, 0.33304667472839355, 0.5994840264320374, 0.8651543855667114, 0.08651543408632278, 0.20803995430469513, 0.7281398773193359, 0.05200998857617378, 0.08412791043519974, 0.08412791043519974, 0.8412790894508362, 0.20799924433231354, 0.13866616785526276, 0.6239977478981018, 0.8975796103477478, 0.06904458999633789, 0.16941778361797333, 0.2541266977787018, 0.5929622650146484, 0.939356803894043, 0.8938300013542175, 0.08125726878643036, 0.08125726878643036, 0.8281213641166687, 0.11830304563045502, 0.08667394518852234, 0.08667394518852234, 0.8667394518852234, 0.7255211472511292, 0.16122692823410034, 0.08061346411705017, 0.8522730469703674, 0.06089860945940018, 0.7307832837104797, 0.18269582092761993, 0.23382139205932617, 0.50661301612854, 0.23382139205932617, 0.3326423168182373, 0.05544038861989975, 0.5544039011001587, 0.24652278423309326, 0.6847854852676392, 0.08217426389455795, 0.41017937660217285, 0.4687764346599579, 0.11719410866498947, 0.20075659453868866, 0.6022697687149048, 0.3011348843574524, 0.9269709587097168, 0.1158713698387146, 0.9224156737327576, 0.6277797222137451, 0.23541739583015442, 0.07847246527671814, 0.9397750496864319, 0.0654953345656395, 0.130990669131279, 0.7859440445899963, 0.05967959761619568, 0.17903879284858704, 0.7758347392082214, 0.9225923418998718, 0.9163427352905273, 0.41082262992858887, 0.5135282874107361, 0.8968420028686523, 0.13394424319267273, 0.2009163796901703, 0.669721245765686, 0.5994890332221985, 0.1712825745344162, 0.1712825745344162, 0.9196879863739014, 0.1532813310623169, 0.051759205758571625, 0.7763881087303162, 0.15527762472629547, 0.41755545139312744, 0.06959258019924164, 0.4871480464935303, 0.9588888883590698, 0.06392592936754227, 0.8892316222190857, 0.05928210914134979, 0.05928210914134979, 0.4770604968070984, 0.0596325621008873, 0.4770604968070984, 0.11148885637521744, 0.2787221372127533, 0.6131886839866638, 0.19782575964927673, 0.6923901438713074, 0.19782575964927673, 0.34688305854797363, 0.08672076463699341, 0.6070453524589539, 0.9311476349830627, 0.042324893176555634, 0.042324893176555634, 0.86224365234375, 0.053890228271484375, 0.10778045654296875, 0.37644633650779724, 0.10755609720945358, 0.5377804636955261, 0.09357699006795883, 0.09357699006795883, 0.8421928882598877, 0.3762541711330414, 0.16125179827213287, 0.4300047755241394, 0.922509491443634, 0.6269914507865906, 0.06966571509838104, 0.348328560590744, 0.10572203993797302, 0.10572203993797302, 0.7400542497634888, 0.48931097984313965, 0.08155183494091034, 0.4077591598033905, 0.21573896706104279, 0.7335124611854553, 0.04314779117703438, 0.15146708488464355, 0.5301347970962524, 0.3029341697692871, 0.8874302506446838, 0.08067548274993896, 0.08067548274993896], \"Term\": [\"amaz\", \"amaz\", \"april\", \"april\", \"april\", \"ask\", \"ask\", \"ask\", \"basi\", \"break\", \"break\", \"break\", \"call\", \"call\", \"call\", \"care\", \"care\", \"care\", \"case\", \"case\", \"case\", \"cast\", \"caus\", \"caus\", \"ceas\", \"china\", \"china\", \"china\", \"confirm\", \"confirm\", \"confirm\", \"corona\", \"corona\", \"corona\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"countri\", \"countri\", \"countri\", \"cover\", \"cover\", \"cover\", \"crisi\", \"crisi\", \"crisi\", \"death\", \"death\", \"death\", \"die\", \"die\", \"die\", \"discrimin\", \"doctor\", \"doctor\", \"doctor\", \"either\", \"either\", \"either\", \"enough\", \"equip\", \"equip\", \"equip\", \"everyon\", \"everyon\", \"everyon\", \"face\", \"face\", \"father\", \"father\", \"father\", \"fight\", \"fight\", \"fight\", \"first\", \"first\", \"first\", \"global\", \"global\", \"global\", \"govern\", \"govern\", \"govern\", \"governor\", \"governor\", \"governor\", \"great\", \"great\", \"great\", \"gullibl\", \"health\", \"health\", \"health\", \"help\", \"help\", \"help\", \"home\", \"home\", \"home\", \"hospit\", \"hospit\", \"hospit\", \"human\", \"human\", \"human\", \"india\", \"india\", \"isol\", \"isol\", \"isol\", \"keep\", \"keep\", \"keep\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"live\", \"live\", \"live\", \"look\", \"look\", \"make\", \"make\", \"make\", \"mask\", \"mask\", \"mask\", \"medic\", \"medic\", \"medic\", \"murder\", \"murder\", \"must\", \"must\", \"must\", \"narrat\", \"nation\", \"nation\", \"nation\", \"natur\", \"natur\", \"never\", \"never\", \"never\", \"nurs\", \"nurs\", \"nurs\", \"often\", \"order\", \"order\", \"order\", \"pandem\", \"pandem\", \"pandem\", \"patient\", \"patient\", \"patient\", \"peopl\", \"peopl\", \"peopl\", \"pleas\", \"pleas\", \"pleas\", \"polic\", \"polic\", \"polic\", \"poor\", \"poor\", \"poverti\", \"presid\", \"presid\", \"presid\", \"propaganda\", \"protect\", \"protect\", \"protect\", \"public\", \"public\", \"public\", \"racism\", \"recommend\", \"releas\", \"releas\", \"religion\", \"report\", \"report\", \"report\", \"respons\", \"respons\", \"respons\", \"rich\", \"rich\", \"say\", \"say\", \"say\", \"send\", \"send\", \"send\", \"speak\", \"speak\", \"spread\", \"spread\", \"spread\", \"state\", \"state\", \"state\", \"stay\", \"stay\", \"stay\", \"support\", \"support\", \"support\", \"take\", \"take\", \"take\", \"test\", \"test\", \"test\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"total\", \"total\", \"total\", \"trump\", \"trump\", \"trump\", \"trut\", \"virus\", \"virus\", \"virus\", \"watch\", \"watch\", \"watch\", \"week\", \"week\", \"week\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"world\", \"world\", \"world\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2179951290965285093487438\", ldavis_el2179951290965285093487438_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2179951290965285093487438\", ldavis_el2179951290965285093487438_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2179951290965285093487438\", ldavis_el2179951290965285093487438_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.075852  0.115277       1        1  34.795292\n",
       "1     -0.170799 -0.008283       2        1  33.261570\n",
       "2      0.094947 -0.106994       3        1  31.943134, topic_info=    Category       Freq         Term      Total  loglift  logprob\n",
       "11   Default  23.000000         test  23.000000  30.0000  30.0000\n",
       "22   Default  23.000000         mask  23.000000  29.0000  29.0000\n",
       "37   Default  15.000000        speak  15.000000  28.0000  28.0000\n",
       "35   Default  14.000000      poverti  14.000000  27.0000  27.0000\n",
       "36   Default  14.000000       racism  14.000000  26.0000  26.0000\n",
       "38   Default  14.000000         trut  14.000000  25.0000  25.0000\n",
       "32   Default  14.000000       father  14.000000  24.0000  24.0000\n",
       "33   Default  14.000000       murder  14.000000  23.0000  23.0000\n",
       "31   Default  15.000000         caus  15.000000  22.0000  22.0000\n",
       "20   Default  36.000000        peopl  36.000000  21.0000  21.0000\n",
       "9    Default  16.000000       spread  16.000000  20.0000  20.0000\n",
       "18   Default  13.000000        first  13.000000  19.0000  19.0000\n",
       "46   Default  18.000000         time  18.000000  18.0000  18.0000\n",
       "34   Default  16.000000        natur  16.000000  17.0000  17.0000\n",
       "48   Default  33.000000         case  33.000000  16.0000  16.0000\n",
       "10   Default  19.000000          say  19.000000  15.0000  15.0000\n",
       "39   Default  23.000000         work  23.000000  14.0000  14.0000\n",
       "73   Default  11.000000         look  11.000000  13.0000  13.0000\n",
       "40   Default  15.000000       govern  15.000000  12.0000  12.0000\n",
       "15   Default  16.000000       public  16.000000  11.0000  11.0000\n",
       "89   Default  15.000000      protect  15.000000  10.0000  10.0000\n",
       "78   Default  11.000000        never  11.000000   9.0000   9.0000\n",
       "51   Default  12.000000        world  12.000000   8.0000   8.0000\n",
       "6    Default  22.000000         help  22.000000   7.0000   7.0000\n",
       "26   Default  12.000000       nation  12.000000   6.0000   6.0000\n",
       "1    Default  19.000000         home  19.000000   5.0000   5.0000\n",
       "16   Default  12.000000        human  12.000000   4.0000   4.0000\n",
       "67   Default  19.000000         make  19.000000   3.0000   3.0000\n",
       "54   Default  12.000000        crisi  12.000000   2.0000   2.0000\n",
       "91   Default   8.000000    recommend   8.000000   1.0000   1.0000\n",
       "11    Topic1  22.052250         test  23.626759   0.9867  -3.1237\n",
       "51    Topic1  11.116374        world  12.395340   0.9468  -3.8087\n",
       "60    Topic1   6.802753    discrimin   7.617075   0.9426  -4.2998\n",
       "50    Topic1   7.155335       enough   8.025694   0.9409  -4.2493\n",
       "26    Topic1  10.946541       nation  12.306591   0.9386  -3.8241\n",
       "9     Topic1  14.848145       spread  16.868496   0.9281  -3.5192\n",
       "63    Topic1   7.582814         poor   8.630260   0.9263  -4.1912\n",
       "58    Topic1   4.837783         basi   5.571973   0.9144  -4.6407\n",
       "64    Topic1   4.804331     religion   5.575118   0.9069  -4.6476\n",
       "59    Topic1   4.788199         cast   5.576118   0.9033  -4.6510\n",
       "46    Topic1  15.778029         time  18.556240   0.8935  -3.4585\n",
       "40    Topic1  13.362967       govern  15.743448   0.8918  -3.6246\n",
       "53    Topic1   8.443399         life   9.989862   0.8875  -4.0837\n",
       "17    Topic1   5.510540         rich   6.523952   0.8869  -4.5105\n",
       "55    Topic1  10.947154        china  13.107110   0.8756  -3.8240\n",
       "62    Topic1  10.927567      everyon  13.201913   0.8666  -3.8258\n",
       "61    Topic1   5.887412       either   7.308793   0.8394  -4.4443\n",
       "8     Topic1   9.464058         nurs  12.404876   0.7851  -3.9696\n",
       "66    Topic1   7.562467        india  10.004038   0.7759  -4.1939\n",
       "6     Topic1  17.233286         help  22.934464   0.7699  -3.3703\n",
       "49    Topic1   8.485822      countri  11.333071   0.7664  -4.0787\n",
       "27    Topic1  13.657109         like  19.242683   0.7128  -3.6029\n",
       "92    Topic1   6.921724     governor  10.551133   0.6341  -4.2825\n",
       "19    Topic1   9.541077       hospit  15.137986   0.5941  -3.9615\n",
       "95    Topic1   8.021397       presid  12.743323   0.5928  -4.1350\n",
       "68    Topic1   8.844735        virus  14.354263   0.5715  -4.0373\n",
       "57    Topic1   7.166625      respons  11.676611   0.5675  -4.2477\n",
       "93    Topic1   6.670333      confirm  11.235033   0.5343  -4.3194\n",
       "24    Topic1   7.428701        april  12.764127   0.5144  -4.2118\n",
       "80    Topic1   6.300741         week  12.262140   0.3898  -4.3764\n",
       "0     Topic1  11.270759       health  24.195366   0.2917  -3.7949\n",
       "65    Topic1   9.994939        fight  21.535294   0.2881  -3.9150\n",
       "5     Topic1  14.896080  coronavirus  45.948059  -0.0707  -3.5160\n",
       "48    Topic1  11.667957         case  33.005905   0.0158  -3.7603\n",
       "3     Topic1   7.682791        state  16.769361   0.2751  -4.1781\n",
       "20    Topic1   9.201370        peopl  36.507782  -0.3225  -3.9978\n",
       "81    Topic1   7.438246        pleas  17.065704   0.2253  -4.2105\n",
       "98    Topic1   7.259205        trump  18.604445   0.1146  -4.2348\n",
       "37    Topic2  14.668909        speak  15.643106   1.0365  -3.4863\n",
       "35    Topic2  13.197689      poverti  14.093430   1.0351  -3.5920\n",
       "36    Topic2  13.170541       racism  14.090731   1.0332  -3.5941\n",
       "38    Topic2  13.159279         trut  14.091996   1.0323  -3.5949\n",
       "33    Topic2  13.362162       murder  14.483395   1.0202  -3.5796\n",
       "32    Topic2  13.705579       father  14.935687   1.0148  -3.5542\n",
       "31    Topic2  13.875563         caus  15.308342   1.0025  -3.5419\n",
       "73    Topic2  10.471901         look  11.558631   1.0020  -3.8233\n",
       "16    Topic2  10.246737        human  12.116035   0.9332  -3.8451\n",
       "54    Topic2  10.314840        crisi  12.245217   0.9292  -3.8385\n",
       "34    Topic2  14.235858        natur  16.905735   0.9289  -3.5163\n",
       "10    Topic2  15.342263          say  19.320234   0.8702  -3.4414\n",
       "69    Topic2   8.612298        great  10.865982   0.8683  -4.0188\n",
       "85    Topic2  10.157415         call  13.210404   0.8380  -3.8538\n",
       "82    Topic2   7.993076       corona  10.448048   0.8329  -4.0935\n",
       "2     Topic2  12.436635        order  16.420736   0.8229  -3.6514\n",
       "1     Topic2  14.690523         home  19.613815   0.8117  -3.4848\n",
       "41    Topic2   7.394185         isol   9.887892   0.8102  -4.1713\n",
       "39    Topic2  16.968019         work  23.176157   0.7890  -3.3407\n",
       "67    Topic2  13.938870         make  19.227076   0.7791  -3.5374\n",
       "83    Topic2   9.880768          die  14.108507   0.7446  -3.8814\n",
       "30    Topic2   6.879885      support  10.109907   0.7159  -4.2434\n",
       "20    Topic2  24.773329        peopl  36.507782   0.7130  -2.9623\n",
       "72    Topic2   7.782260        equip  11.938435   0.6729  -4.1202\n",
       "86    Topic2   8.035432        break  13.619613   0.5731  -4.0882\n",
       "90    Topic2   5.823747        polic   9.962313   0.5639  -4.4101\n",
       "70    Topic2   7.415824       worker  13.204189   0.5238  -4.1684\n",
       "14    Topic2  13.378310       pandem  25.660612   0.4494  -3.5784\n",
       "100   Topic2   4.951749       releas   9.736562   0.4246  -4.5723\n",
       "81    Topic2   7.837668        pleas  17.065704   0.3226  -4.1131\n",
       "65    Topic2   8.882753        fight  21.535294   0.2152  -3.9879\n",
       "0     Topic2   6.950749       health  24.195366  -0.1465  -4.2332\n",
       "5     Topic2   7.425506  coronavirus  45.948059  -0.7218  -4.1671\n",
       "91    Topic3   7.886380    recommend   8.730358   1.0395  -4.0665\n",
       "18    Topic3  12.037541        first  13.399345   1.0340  -3.6436\n",
       "21    Topic3   6.308627        often   7.039998   1.0315  -4.2897\n",
       "75    Topic3   5.694179         ceas   6.389342   1.0260  -4.3921\n",
       "77    Topic3   5.670969       narrat   6.387349   1.0223  -4.3962\n",
       "76    Topic3   5.629767      gullibl   6.385216   1.0153  -4.4035\n",
       "79    Topic3   5.628182   propaganda   6.384507   1.0151  -4.4038\n",
       "78    Topic3  10.106188        never  11.537493   1.0088  -3.8184\n",
       "74    Topic3   6.632556         amaz   7.610064   1.0037  -4.2396\n",
       "22    Topic3  19.952774         mask  23.773323   0.9660  -3.1382\n",
       "87    Topic3   8.867621        total  10.686388   0.9546  -3.9492\n",
       "89    Topic3  12.239707      protect  15.268263   0.9201  -3.6269\n",
       "99    Topic3   7.149067        cover   8.952730   0.9162  -4.1646\n",
       "96    Topic3   7.460005        watch   9.458766   0.9038  -4.1220\n",
       "15    Topic3  12.961347       public  16.756145   0.8844  -3.5696\n",
       "94    Topic3   8.881083         face  11.757040   0.8607  -3.9477\n",
       "43    Topic3  10.076792       report  14.931585   0.7480  -3.8214\n",
       "29    Topic3   9.249479        medic  14.423129   0.6969  -3.9070\n",
       "84    Topic3   7.848502          ask  12.309867   0.6911  -4.0713\n",
       "7     Topic3  12.305882         keep  19.349792   0.6886  -3.6215\n",
       "56    Topic3   7.176236         must  11.805136   0.6435  -4.1608\n",
       "42    Topic3  11.454081        death  18.962963   0.6371  -3.6932\n",
       "12    Topic3   7.663394       doctor  12.840359   0.6251  -4.0951\n",
       "48    Topic3  19.617672         case  33.005905   0.6210  -3.1552\n",
       "4     Topic3  10.569308         stay  17.939013   0.6122  -3.7736\n",
       "71    Topic3   8.784344         live  15.012911   0.6053  -3.9586\n",
       "13    Topic3   6.056656       global  10.422430   0.5984  -4.3304\n",
       "45    Topic3  10.459094      patient  18.037392   0.5962  -3.7841\n",
       "101   Topic3   6.535457         take  11.531263   0.5734  -4.2544\n",
       "28    Topic3  10.212078        today  18.594948   0.5419  -3.8080\n",
       "5     Topic3  23.626471  coronavirus  45.948059   0.4761  -2.9692\n",
       "3     Topic3   8.488895        state  16.769361   0.4604  -3.9928\n",
       "23    Topic3   7.398921         send  14.369349   0.4774  -4.1303\n",
       "98    Topic3   7.953731        trump  18.604445   0.2915  -4.0580\n",
       "44    Topic3   6.586510         care  15.546556   0.2824  -4.2466, token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "74        1  0.131405         amaz\n",
       "74        3  0.919835         amaz\n",
       "24        1  0.548412        april\n",
       "24        2  0.078345        april\n",
       "24        3  0.391723        april\n",
       "84        1  0.162471          ask\n",
       "84        2  0.243707          ask\n",
       "84        3  0.649885          ask\n",
       "58        1  0.897348         basi\n",
       "86        1  0.293694        break\n",
       "86        2  0.587388        break\n",
       "86        3  0.146847        break\n",
       "85        1  0.151396         call\n",
       "85        2  0.756979         call\n",
       "85        3  0.075698         call\n",
       "44        1  0.192969         care\n",
       "44        2  0.385938         care\n",
       "44        3  0.450260         care\n",
       "48        1  0.363571         case\n",
       "48        2  0.060595         case\n",
       "48        3  0.605952         case\n",
       "59        1  0.896681         cast\n",
       "31        2  0.914534         caus\n",
       "31        3  0.065324         caus\n",
       "75        3  0.939064         ceas\n",
       "55        1  0.839239        china\n",
       "55        2  0.076294        china\n",
       "55        3  0.076294        china\n",
       "93        1  0.623051      confirm\n",
       "93        2  0.356029      confirm\n",
       "93        3  0.089007      confirm\n",
       "82        1  0.095712       corona\n",
       "82        2  0.765693       corona\n",
       "82        3  0.095712       corona\n",
       "5         1  0.326456  coronavirus\n",
       "5         2  0.152346  coronavirus\n",
       "5         3  0.522329  coronavirus\n",
       "49        1  0.705899      countri\n",
       "49        2  0.088237      countri\n",
       "49        3  0.176475      countri\n",
       "99        1  0.111698        cover\n",
       "99        2  0.111698        cover\n",
       "99        3  0.781884        cover\n",
       "54        1  0.081665        crisi\n",
       "54        2  0.816645        crisi\n",
       "54        3  0.081665        crisi\n",
       "42        1  0.316406        death\n",
       "42        2  0.105469        death\n",
       "42        3  0.580078        death\n",
       "83        1  0.212638          die\n",
       "83        2  0.708792          die\n",
       "83        3  0.070879          die\n",
       "60        1  0.918988    discrimin\n",
       "12        1  0.389397       doctor\n",
       "12        2  0.077879       doctor\n",
       "12        3  0.623036       doctor\n",
       "61        1  0.820929       either\n",
       "61        2  0.136821       either\n",
       "61        3  0.136821       either\n",
       "50        1  0.872199       enough\n",
       "72        1  0.251289        equip\n",
       "72        2  0.670105        equip\n",
       "72        3  0.083763        equip\n",
       "62        1  0.833213      everyon\n",
       "62        2  0.151493      everyon\n",
       "62        3  0.075747      everyon\n",
       "94        1  0.170111         face\n",
       "94        3  0.765499         face\n",
       "32        1  0.066954       father\n",
       "32        2  0.937352       father\n",
       "32        3  0.066954       father\n",
       "65        1  0.464354        fight\n",
       "65        2  0.417919        fight\n",
       "65        3  0.139306        fight\n",
       "18        1  0.074631        first\n",
       "18        2  0.074631        first\n",
       "18        3  0.895566        first\n",
       "13        1  0.287841       global\n",
       "13        2  0.095947       global\n",
       "13        3  0.575682       global\n",
       "40        1  0.825740       govern\n",
       "40        2  0.127037       govern\n",
       "40        3  0.063518       govern\n",
       "92        1  0.663436     governor\n",
       "92        2  0.094777     governor\n",
       "92        3  0.189553     governor\n",
       "69        1  0.092030        great\n",
       "69        2  0.828273        great\n",
       "69        3  0.184061        great\n",
       "76        3  0.939671      gullibl\n",
       "0         1  0.454633       health\n",
       "0         2  0.289312       health\n",
       "0         3  0.247981       health\n",
       "6         1  0.741243         help\n",
       "6         2  0.087205         help\n",
       "6         3  0.174410         help\n",
       "1         1  0.101969         home\n",
       "1         2  0.764767         home\n",
       "1         3  0.152953         home\n",
       "19        1  0.660590       hospit\n",
       "19        2  0.264236       hospit\n",
       "19        3  0.132118       hospit\n",
       "16        1  0.082535        human\n",
       "16        2  0.825352        human\n",
       "16        3  0.082535        human\n",
       "66        1  0.799677        india\n",
       "66        3  0.199919        india\n",
       "41        1  0.202268         isol\n",
       "41        2  0.707937         isol\n",
       "41        3  0.101134         isol\n",
       "7         1  0.155040         keep\n",
       "7         2  0.206721         keep\n",
       "7         3  0.620162         keep\n",
       "53        1  0.800812         life\n",
       "53        2  0.100101         life\n",
       "53        3  0.100101         life\n",
       "27        1  0.727549         like\n",
       "27        2  0.207871         like\n",
       "27        3  0.103936         like\n",
       "71        1  0.066609         live\n",
       "71        2  0.333047         live\n",
       "71        3  0.599484         live\n",
       "73        2  0.865154         look\n",
       "73        3  0.086515         look\n",
       "67        1  0.208040         make\n",
       "67        2  0.728140         make\n",
       "67        3  0.052010         make\n",
       "22        1  0.084128         mask\n",
       "22        2  0.084128         mask\n",
       "22        3  0.841279         mask\n",
       "29        1  0.207999        medic\n",
       "29        2  0.138666        medic\n",
       "29        3  0.623998        medic\n",
       "33        2  0.897580       murder\n",
       "33        3  0.069045       murder\n",
       "56        1  0.169418         must\n",
       "56        2  0.254127         must\n",
       "56        3  0.592962         must\n",
       "77        3  0.939357       narrat\n",
       "26        1  0.893830       nation\n",
       "26        2  0.081257       nation\n",
       "26        3  0.081257       nation\n",
       "34        2  0.828121        natur\n",
       "34        3  0.118303        natur\n",
       "78        1  0.086674        never\n",
       "78        2  0.086674        never\n",
       "78        3  0.866739        never\n",
       "8         1  0.725521         nurs\n",
       "8         2  0.161227         nurs\n",
       "8         3  0.080613         nurs\n",
       "21        3  0.852273        often\n",
       "2         1  0.060899        order\n",
       "2         2  0.730783        order\n",
       "2         3  0.182696        order\n",
       "14        1  0.233821       pandem\n",
       "14        2  0.506613       pandem\n",
       "14        3  0.233821       pandem\n",
       "45        1  0.332642      patient\n",
       "45        2  0.055440      patient\n",
       "45        3  0.554404      patient\n",
       "20        1  0.246523        peopl\n",
       "20        2  0.684785        peopl\n",
       "20        3  0.082174        peopl\n",
       "81        1  0.410179        pleas\n",
       "81        2  0.468776        pleas\n",
       "81        3  0.117194        pleas\n",
       "90        1  0.200757        polic\n",
       "90        2  0.602270        polic\n",
       "90        3  0.301135        polic\n",
       "63        1  0.926971         poor\n",
       "63        3  0.115871         poor\n",
       "35        2  0.922416      poverti\n",
       "95        1  0.627780       presid\n",
       "95        2  0.235417       presid\n",
       "95        3  0.078472       presid\n",
       "79        3  0.939775   propaganda\n",
       "89        1  0.065495      protect\n",
       "89        2  0.130991      protect\n",
       "89        3  0.785944      protect\n",
       "15        1  0.059680       public\n",
       "15        2  0.179039       public\n",
       "15        3  0.775835       public\n",
       "36        2  0.922592       racism\n",
       "91        3  0.916343    recommend\n",
       "100       1  0.410823       releas\n",
       "100       2  0.513528       releas\n",
       "64        1  0.896842     religion\n",
       "43        1  0.133944       report\n",
       "43        2  0.200916       report\n",
       "43        3  0.669721       report\n",
       "57        1  0.599489      respons\n",
       "57        2  0.171283      respons\n",
       "57        3  0.171283      respons\n",
       "17        1  0.919688         rich\n",
       "17        2  0.153281         rich\n",
       "10        1  0.051759          say\n",
       "10        2  0.776388          say\n",
       "10        3  0.155278          say\n",
       "23        1  0.417555         send\n",
       "23        2  0.069593         send\n",
       "23        3  0.487148         send\n",
       "37        2  0.958889        speak\n",
       "37        3  0.063926        speak\n",
       "9         1  0.889232       spread\n",
       "9         2  0.059282       spread\n",
       "9         3  0.059282       spread\n",
       "3         1  0.477060        state\n",
       "3         2  0.059633        state\n",
       "3         3  0.477060        state\n",
       "4         1  0.111489         stay\n",
       "4         2  0.278722         stay\n",
       "4         3  0.613189         stay\n",
       "30        1  0.197826      support\n",
       "30        2  0.692390      support\n",
       "30        3  0.197826      support\n",
       "101       1  0.346883         take\n",
       "101       2  0.086721         take\n",
       "101       3  0.607045         take\n",
       "11        1  0.931148         test\n",
       "11        2  0.042325         test\n",
       "11        3  0.042325         test\n",
       "46        1  0.862244         time\n",
       "46        2  0.053890         time\n",
       "46        3  0.107780         time\n",
       "28        1  0.376446        today\n",
       "28        2  0.107556        today\n",
       "28        3  0.537780        today\n",
       "87        1  0.093577        total\n",
       "87        2  0.093577        total\n",
       "87        3  0.842193        total\n",
       "98        1  0.376254        trump\n",
       "98        2  0.161252        trump\n",
       "98        3  0.430005        trump\n",
       "38        2  0.922509         trut\n",
       "68        1  0.626991        virus\n",
       "68        2  0.069666        virus\n",
       "68        3  0.348329        virus\n",
       "96        1  0.105722        watch\n",
       "96        2  0.105722        watch\n",
       "96        3  0.740054        watch\n",
       "80        1  0.489311         week\n",
       "80        2  0.081552         week\n",
       "80        3  0.407759         week\n",
       "39        1  0.215739         work\n",
       "39        2  0.733512         work\n",
       "39        3  0.043148         work\n",
       "70        1  0.151467       worker\n",
       "70        2  0.530135       worker\n",
       "70        3  0.302934       worker\n",
       "51        1  0.887430        world\n",
       "51        2  0.080675        world\n",
       "51        3  0.080675        world, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model_tfidf, corpus_tfidf, dictionary=lda_model_tfidf.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be 3 topics from the visualizations. \n",
    "\n",
    "### 5.1.3 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test tweet is: 0: ['health', 'home', 'order', 'state', 'stay']\n",
      "\n",
      "Score: 0.4609680473804474\t \n",
      "Topic: 1 : 0.054*\"case\" + 0.048*\"coronavirus\" + 0.045*\"work\" + 0.041*\"natur\" + 0.038*\"speak\" + 0.037*\"caus\" + 0.037*\"father\" + 0.036*\"murder\" + 0.036*\"poverti\" + 0.036*\"racism\"\n",
      "\n",
      "Score: 0.41478097438812256\t \n",
      "Topic: 2 : 0.052*\"pandem\" + 0.044*\"health\" + 0.044*\"mask\" + 0.041*\"home\" + 0.039*\"stay\" + 0.035*\"test\" + 0.033*\"order\" + 0.028*\"presid\" + 0.024*\"help\" + 0.023*\"public\"\n",
      "\n",
      "Score: 0.12425100058317184\t \n",
      "Topic: 0 : 0.062*\"peopl\" + 0.033*\"death\" + 0.031*\"coronavirus\" + 0.030*\"keep\" + 0.027*\"like\" + 0.024*\"care\" + 0.023*\"spread\" + 0.023*\"today\" + 0.021*\"face\" + 0.021*\"human\"\n"
     ]
    }
   ],
   "source": [
    "# Our test tweet is \n",
    "print('Our test tweet is: {}: {}'.format(tweet_num, [dictionary[word[0]] for word in corpus_tfidf[tweet_num]]))\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[corpus_tfidf[tweet_num]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {} : {}\".format(score, index, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the sample tweet is split between topics 1 and 2. As we saw in the section 4.2.1, Topic 1 was centere around Impact of COVID in terms of patients, deaths and lockdowns and Topic 2 around Quarantine and fight the spread of COVID-19. The sample tweet matches better with Topic 2. But, the modeling didn't classify it correctly or rather didn't have good confidence in the classification. This was expected as TF-IDF doesn't work good for short text documents. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "EarlyIndicatorsFromNews",
  "notebookId": 3907296281459545
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
